{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d819d5a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:04:59.297072Z",
     "iopub.status.busy": "2023-06-28T02:04:59.296187Z",
     "iopub.status.idle": "2023-06-28T02:05:01.119905Z",
     "shell.execute_reply": "2023-06-28T02:05:01.118868Z"
    },
    "papermill": {
     "duration": 1.845601,
     "end_time": "2023-06-28T02:05:01.123320",
     "exception": false,
     "start_time": "2023-06-28T02:04:59.277719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bd9b5c",
   "metadata": {
    "papermill": {
     "duration": 0.013386,
     "end_time": "2023-06-28T02:05:01.151278",
     "exception": false,
     "start_time": "2023-06-28T02:05:01.137892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Train Data and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf58c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:01.186978Z",
     "iopub.status.busy": "2023-06-28T02:05:01.185783Z",
     "iopub.status.idle": "2023-06-28T02:05:01.194637Z",
     "shell.execute_reply": "2023-06-28T02:05:01.193520Z"
    },
    "papermill": {
     "duration": 0.033803,
     "end_time": "2023-06-28T02:05:01.198575",
     "exception": false,
     "start_time": "2023-06-28T02:05:01.164772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dtypes = {\"session_id\": 'int64',\n",
    "          \"index\": np.int16,\n",
    "          \"elapsed_time\": np.int32,\n",
    "          \"event_name\": 'category',\n",
    "          \"name\": 'category',\n",
    "          \"level\": np.int8,\n",
    "          \"page\": np.float16,\n",
    "          \"room_coor_x\": np.float16,\n",
    "          \"room_coor_y\": np.float16,\n",
    "          \"screen_coor_x\": np.float16,\n",
    "          \"screen_coor_y\": np.float16,\n",
    "          \"hover_duration\": np.float32,\n",
    "          \"text\": 'category',\n",
    "          \"fqid\": 'category',\n",
    "          \"room_fqid\": 'category',\n",
    "          \"text_fqid\": 'category',\n",
    "          \"fullscreen\": np.int8,\n",
    "          \"hq\": np.int8,\n",
    "          \"music\": np.int8,\n",
    "          \"level_group\": 'category'\n",
    "          }\n",
    "use_col = ['session_id', 'index', 'elapsed_time', 'event_name', 'name', 'level', 'page',\n",
    "           'room_coor_x', 'room_coor_y', 'hover_duration', 'text', 'fqid', 'room_fqid', 'text_fqid', 'level_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e46dc7c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:01.241026Z",
     "iopub.status.busy": "2023-06-28T02:05:01.240200Z",
     "iopub.status.idle": "2023-06-28T02:05:02.669420Z",
     "shell.execute_reply": "2023-06-28T02:05:02.668114Z"
    },
    "papermill": {
     "duration": 1.45348,
     "end_time": "2023-06-28T02:05:02.672163",
     "exception": false,
     "start_time": "2023-06-28T02:05:01.218683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(424116, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "      <th>session</th>\n",
       "      <th>q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312431273200_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090312431273200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312433251036_q1</td>\n",
       "      <td>0</td>\n",
       "      <td>20090312433251036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312455206810_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090312455206810</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090313091715820_q1</td>\n",
       "      <td>0</td>\n",
       "      <td>20090313091715820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090313571836404_q1</td>\n",
       "      <td>1</td>\n",
       "      <td>20090313571836404</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct            session  q\n",
       "0  20090312431273200_q1        1  20090312431273200  1\n",
       "1  20090312433251036_q1        0  20090312433251036  1\n",
       "2  20090312455206810_q1        1  20090312455206810  1\n",
       "3  20090313091715820_q1        0  20090313091715820  1\n",
       "4  20090313571836404_q1        1  20090313571836404  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train_labels.csv')\n",
    "targets['session'] = targets.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "targets['q'] = targets.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
    "print( targets.shape )\n",
    "targets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64c4a148",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:02.704328Z",
     "iopub.status.busy": "2023-06-28T02:05:02.702938Z",
     "iopub.status.idle": "2023-06-28T02:05:02.877901Z",
     "shell.execute_reply": "2023-06-28T02:05:02.876964Z"
    },
    "papermill": {
     "duration": 0.194431,
     "end_time": "2023-06-28T02:05:02.880782",
     "exception": false,
     "start_time": "2023-06-28T02:05:02.686351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_df = pd.read_csv('/kaggle/input/featur/feature_sort.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4ad38c",
   "metadata": {
    "papermill": {
     "duration": 0.013185,
     "end_time": "2023-06-28T02:05:02.907622",
     "exception": false,
     "start_time": "2023-06-28T02:05:02.894437",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae100b66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:02.937977Z",
     "iopub.status.busy": "2023-06-28T02:05:02.937152Z",
     "iopub.status.idle": "2023-06-28T02:05:02.944890Z",
     "shell.execute_reply": "2023-06-28T02:05:02.943423Z"
    },
    "papermill": {
     "duration": 0.025889,
     "end_time": "2023-06-28T02:05:02.947751",
     "exception": false,
     "start_time": "2023-06-28T02:05:02.921862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delt_time_def(df):\n",
    "    df.sort_values(by=['session_id', 'elapsed_time'], inplace=True)\n",
    "    df['d_time'] = df['elapsed_time'].diff(1)\n",
    "    df['d_time'].fillna(0, inplace=True)\n",
    "    df['delt_time'] = df['d_time'].clip(0, 103000)\n",
    "    df['delt_time_next'] = df['delt_time'].shift(-1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42152835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:02.978320Z",
     "iopub.status.busy": "2023-06-28T02:05:02.977403Z",
     "iopub.status.idle": "2023-06-28T02:05:02.991257Z",
     "shell.execute_reply": "2023-06-28T02:05:02.990062Z"
    },
    "papermill": {
     "duration": 0.032208,
     "end_time": "2023-06-28T02:05:02.994099",
     "exception": false,
     "start_time": "2023-06-28T02:05:02.961891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer(train, kol_f):\n",
    "    global kol_col, kol_col_max\n",
    "    kol_col = 9\n",
    "    kol_col_max = 11+kol_f*2\n",
    "    col = [i for i in range(0,kol_col_max)]\n",
    "    new_train = pd.DataFrame(index=train['session_id'].unique(), columns=col, dtype=np.float16)  \n",
    "    new_train[10] = new_train.index # \"session_id\"    \n",
    "\n",
    "    new_train[0] = train.groupby(['session_id'])['d_time'].quantile(q=0.3)\n",
    "    new_train[1] = train.groupby(['session_id'])['d_time'].quantile(q=0.8)\n",
    "    new_train[2] = train.groupby(['session_id'])['d_time'].quantile(q=0.5)\n",
    "    new_train[3] = train.groupby(['session_id'])['d_time'].quantile(q=0.65)\n",
    "    new_train[4] = train.groupby(['session_id'])['hover_duration'].agg('mean')\n",
    "    new_train[5] = train.groupby(['session_id'])['hover_duration'].agg('std')    \n",
    "    new_train[6] = new_train[10].apply(lambda x: int(str(x)[:2])).astype(np.uint8) # \"year\"\n",
    "    new_train[7] = new_train[10].apply(lambda x: int(str(x)[2:4])+1).astype(np.uint8) # \"month\"\n",
    "    new_train[8] = new_train[10].apply(lambda x: int(str(x)[4:6])).astype(np.uint8) # \"day\"\n",
    "    new_train[9] = new_train[10].apply(lambda x: int(str(x)[6:8])).astype(np.uint8) + new_train[10].apply(lambda x: int(str(x)[8:10])).astype(np.uint8)/60\n",
    "    new_train[10] = 0\n",
    "    new_train = new_train.fillna(-1)\n",
    "    \n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6ba837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.024718Z",
     "iopub.status.busy": "2023-06-28T02:05:03.023679Z",
     "iopub.status.idle": "2023-06-28T02:05:03.034886Z",
     "shell.execute_reply": "2023-06-28T02:05:03.033492Z"
    },
    "papermill": {
     "duration": 0.029844,
     "end_time": "2023-06-28T02:05:03.037800",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.007956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_next_t(row_f, new_train, train, gran_1, gran_2, i):\n",
    "    global kol_col\n",
    "    kol_col +=1\n",
    "    col1 = row_f['col1']\n",
    "    val1 = row_f['val1']\n",
    "    maska = (train[col1] == val1)\n",
    "    if row_f['kol_col'] == 1:       \n",
    "        new_train[kol_col] = train[maska].groupby(['session_id'])['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska].groupby(['session_id'])['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska].groupby(['session_id'])['index'].count()          \n",
    "    elif row_f['kol_col'] == 2: \n",
    "        col2 = row_f['col2']\n",
    "        val2 = row_f['val2']\n",
    "        maska = maska & (train[col2] == val2)        \n",
    "        new_train[kol_col] = train[maska].groupby(['session_id'])['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska].groupby(['session_id'])['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska].groupby(['session_id'])['index'].count()\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbaea803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.067769Z",
     "iopub.status.busy": "2023-06-28T02:05:03.066972Z",
     "iopub.status.idle": "2023-06-28T02:05:03.077099Z",
     "shell.execute_reply": "2023-06-28T02:05:03.075769Z"
    },
    "papermill": {
     "duration": 0.028066,
     "end_time": "2023-06-28T02:05:03.079772",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.051706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_next_t_otvet(row_f, new_train, train, gran_1, gran_2, i):\n",
    "    global kol_col\n",
    "    kol_col +=1\n",
    "    col1 = row_f['col1']\n",
    "    val1 = row_f['val1']\n",
    "    maska = (train[col1] == val1)\n",
    "    if row_f['kol_col'] == 1:      \n",
    "        new_train[kol_col] = train[maska]['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['index'].count()          \n",
    "    elif row_f['kol_col'] == 2: \n",
    "        col2 = row_f['col2']\n",
    "        val2 = row_f['val2']\n",
    "        maska = maska & (train[col2] == val2)        \n",
    "        new_train[kol_col] = train[maska]['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['index'].count()\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e890c62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.110635Z",
     "iopub.status.busy": "2023-06-28T02:05:03.109803Z",
     "iopub.status.idle": "2023-06-28T02:05:03.119529Z",
     "shell.execute_reply": "2023-06-28T02:05:03.118465Z"
    },
    "papermill": {
     "duration": 0.028548,
     "end_time": "2023-06-28T02:05:03.122437",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.093889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def experiment_feature_next_t_otvet(row_f, new_train, train, gran_1, gran_2, i):\n",
    "    global kol_col\n",
    "    kol_col +=1\n",
    "    if row_f['kol_col'] == 1: \n",
    "        maska = train[row_f['col1']] == row_f['val1']\n",
    "        new_train[kol_col] = train[maska]['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['index'].count()          \n",
    "    elif row_f['kol_col'] == 2: \n",
    "        col2 = row_f['col2']\n",
    "        val2 = row_f['val2']\n",
    "        maska = (train[col1] == val1) & (train[col2] == val2)        \n",
    "        new_train[kol_col] = train[maska]['delt_time_next'].sum()\n",
    "        if gran_1:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['delt_time'].mean()\n",
    "        if gran_2:\n",
    "            kol_col +=1\n",
    "            new_train[kol_col] = train[maska]['index'].count()\n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c038ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.154766Z",
     "iopub.status.busy": "2023-06-28T02:05:03.153623Z",
     "iopub.status.idle": "2023-06-28T02:05:03.163061Z",
     "shell.execute_reply": "2023-06-28T02:05:03.161989Z"
    },
    "papermill": {
     "duration": 0.029409,
     "end_time": "2023-06-28T02:05:03.166328",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.136919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_quest_otvet(new_train, train, quest, kol_f):\n",
    "    global kol_col\n",
    "    kol_col = 9\n",
    "    g1 = 0.7 \n",
    "    g2 = 0.3 \n",
    "\n",
    "    feature_q = feature_df[feature_df['quest'] == quest].copy()\n",
    "    feature_q.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    gran1 = round(kol_f * g1)\n",
    "    gran2 = round(kol_f * g2)    \n",
    "    for i in range(0, kol_f):         \n",
    "        row_f = feature_q.loc[i]\n",
    "        new_train = feature_next_t_otvet(row_f, new_train, train, i < gran1, i <  gran2, i) \n",
    "    col = [i for i in range(0,kol_col+1)]\n",
    "    return new_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b18bb016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.197673Z",
     "iopub.status.busy": "2023-06-28T02:05:03.196882Z",
     "iopub.status.idle": "2023-06-28T02:05:03.203187Z",
     "shell.execute_reply": "2023-06-28T02:05:03.202177Z"
    },
    "papermill": {
     "duration": 0.024772,
     "end_time": "2023-06-28T02:05:03.205936",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.181164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer_new(new_train, train, feature_q, kol_f):\n",
    "    g1 = 0.7 \n",
    "    g2 = 0.3 \n",
    "    gran1 = round(kol_f * g1)\n",
    "    gran2 = round(kol_f * g2)    \n",
    "    for i in range(0, kol_f): \n",
    "        row_f = feature_q.loc[i]       \n",
    "        new_train = feature_next_t(row_f, new_train, train, i < gran1, i <  gran2, i)         \n",
    "    return new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a98843ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.237249Z",
     "iopub.status.busy": "2023-06-28T02:05:03.236447Z",
     "iopub.status.idle": "2023-06-28T02:05:03.243069Z",
     "shell.execute_reply": "2023-06-28T02:05:03.242024Z"
    },
    "papermill": {
     "duration": 0.02479,
     "end_time": "2023-06-28T02:05:03.245858",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.221068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_quest(new_train, train, quest, kol_f):\n",
    "    global kol_col\n",
    "    kol_col = 9\n",
    "    feature_q = feature_df[feature_df['quest'] == quest].copy()\n",
    "    feature_q.reset_index(drop=True, inplace=True)\n",
    "    new_train = feature_engineer_new(new_train, train, feature_q, kol_f)\n",
    "    col = [i for i in range(0,kol_col+1)]\n",
    "    return new_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4de2b23b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.277357Z",
     "iopub.status.busy": "2023-06-28T02:05:03.276571Z",
     "iopub.status.idle": "2023-06-28T02:05:03.284879Z",
     "shell.execute_reply": "2023-06-28T02:05:03.283930Z"
    },
    "papermill": {
     "duration": 0.026674,
     "end_time": "2023-06-28T02:05:03.287600",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.260926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(old_train, quests, models, list_kol_f):\n",
    "    \n",
    "    kol_quest = len(quests)\n",
    "    # ITERATE THRU QUESTIONS\n",
    "    for q in quests:\n",
    "        print('### quest ', q, end='')\n",
    "        new_train = feature_engineer(old_train, list_kol_f[q])\n",
    "        train_x = feature_quest(new_train, old_train, q, list_kol_f[q])\n",
    "        print (' ---- ', 'train_q.shape = ', train_x.shape)\n",
    "           \n",
    "        # TRAIN DATA\n",
    "        train_users = train_x.index.values\n",
    "        train_y = targets.loc[targets.q==q].set_index('session').loc[train_users]\n",
    "\n",
    "        # TRAIN MODEL \n",
    "\n",
    "        model = CatBoostClassifier(\n",
    "            n_estimators = 300,\n",
    "            learning_rate= 0.045,\n",
    "            depth = 6\n",
    "        )\n",
    "        \n",
    "        model.fit(train_x.astype('float32'), train_y['correct'], verbose=False)\n",
    "\n",
    "        # SAVE MODEL, PREDICT VALID OOF\n",
    "        models[f'{q}'] = model\n",
    "    print('***')\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78246904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.318310Z",
     "iopub.status.busy": "2023-06-28T02:05:03.317559Z",
     "iopub.status.idle": "2023-06-28T02:05:03.321976Z",
     "shell.execute_reply": "2023-06-28T02:05:03.321042Z"
    },
    "papermill": {
     "duration": 0.022682,
     "end_time": "2023-06-28T02:05:03.324510",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.301828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "best_threshold = 0.63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d14b6ac4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.355042Z",
     "iopub.status.busy": "2023-06-28T02:05:03.354186Z",
     "iopub.status.idle": "2023-06-28T02:05:03.359524Z",
     "shell.execute_reply": "2023-06-28T02:05:03.358673Z"
    },
    "papermill": {
     "duration": 0.022987,
     "end_time": "2023-06-28T02:05:03.361994",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.339007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_kol_f = {\n",
    "    1:140,3:110,\n",
    "    4:120, 5:220, 6:130, 7:110, 8:110, 9:100, 10:140, 11:120,\n",
    "    14: 160, 15:160, 16:130, 17:140             \n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56d118a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:05:03.392129Z",
     "iopub.status.busy": "2023-06-28T02:05:03.390874Z",
     "iopub.status.idle": "2023-06-28T02:06:38.361010Z",
     "shell.execute_reply": "2023-06-28T02:06:38.359184Z"
    },
    "papermill": {
     "duration": 94.988919,
     "end_time": "2023-06-28T02:06:38.364545",
     "exception": false,
     "start_time": "2023-06-28T02:05:03.375626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### quest  1 ----  train_q.shape =  (23562, 290)\n",
      "### quest  3 ----  train_q.shape =  (23562, 230)\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "df0_4 = pd.read_csv('/kaggle/input/featur/train_0_4t.csv', dtype=dtypes) \n",
    "kol_lvl = (df0_4 .groupby(['session_id'])['level'].agg('nunique') < 5)\n",
    "list_session = kol_lvl[kol_lvl].index\n",
    "df0_4  = df0_4 [~df0_4 ['session_id'].isin(list_session)]\n",
    "df0_4 = delt_time_def(df0_4)\n",
    "\n",
    "quests_0_4 = [1, 3] \n",
    "# list_kol_f = {1:140,3:110}\n",
    "\n",
    "models = create_model(df0_4, quests_0_4, models, list_kol_f)\n",
    "del df0_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "095efc69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:06:38.398037Z",
     "iopub.status.busy": "2023-06-28T02:06:38.396830Z",
     "iopub.status.idle": "2023-06-28T02:15:05.258473Z",
     "shell.execute_reply": "2023-06-28T02:15:05.257455Z"
    },
    "papermill": {
     "duration": 506.88117,
     "end_time": "2023-06-28T02:15:05.260954",
     "exception": false,
     "start_time": "2023-06-28T02:06:38.379784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### quest  4 ----  train_q.shape =  (23561, 250)\n",
      "### quest  5 ----  train_q.shape =  (23561, 450)\n",
      "### quest  6 ----  train_q.shape =  (23561, 270)\n",
      "### quest  7 ----  train_q.shape =  (23561, 230)\n",
      "### quest  8 ----  train_q.shape =  (23561, 230)\n",
      "### quest  9 ----  train_q.shape =  (23561, 210)\n",
      "### quest  10 ----  train_q.shape =  (23561, 290)\n",
      "### quest  11 ----  train_q.shape =  (23561, 250)\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "df5_12 = pd.read_csv('/kaggle/input/featur/train_5_12t.csv', dtype=dtypes)\n",
    "kol_lvl = (df5_12.groupby(['session_id'])['level'].agg('nunique') < 8)\n",
    "list_session = kol_lvl[kol_lvl].index\n",
    "df5_12 = df5_12[~df5_12['session_id'].isin(list_session)]\n",
    "df5_12 = delt_time_def(df5_12)\n",
    "quests_5_12 = [4, 5, 6, 7, 8, 9, 10, 11] \n",
    "\n",
    "# list_kol_f = {4:110, 5:220, 6:120, 7:110, 8:110, 9:100, 10:140, 11:120}\n",
    "\n",
    "models = create_model(df5_12, quests_5_12, models, list_kol_f)\n",
    "del df5_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e824e2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:15:05.293728Z",
     "iopub.status.busy": "2023-06-28T02:15:05.292317Z",
     "iopub.status.idle": "2023-06-28T02:20:35.944087Z",
     "shell.execute_reply": "2023-06-28T02:20:35.942831Z"
    },
    "papermill": {
     "duration": 330.671174,
     "end_time": "2023-06-28T02:20:35.947250",
     "exception": false,
     "start_time": "2023-06-28T02:15:05.276076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### quest  14 ----  train_q.shape =  (22986, 330)\n",
      "### quest  15 ----  train_q.shape =  (22986, 330)\n",
      "### quest  16 ----  train_q.shape =  (22986, 270)\n",
      "### quest  17 ----  train_q.shape =  (22986, 290)\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "df13_22 = pd.read_csv('/kaggle/input/featur/train_13_22t.csv', dtype=dtypes) \n",
    "kol_lvl = (df13_22 .groupby(['session_id'])['level'].agg('nunique') < 10)\n",
    "list_session = kol_lvl[kol_lvl].index\n",
    "df13_22  = df13_22 [~df13_22 ['session_id'].isin(list_session)]\n",
    "df13_22 = delt_time_def(df13_22)\n",
    "\n",
    "quests_13_22 = [14, 15, 16, 17] \n",
    "# list_kol_f = {14: 160, 15:160, 16:105, 17:140}\n",
    "\n",
    "models = create_model(df13_22, quests_13_22, models, list_kol_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f72fb33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:35.983102Z",
     "iopub.status.busy": "2023-06-28T02:20:35.981896Z",
     "iopub.status.idle": "2023-06-28T02:20:35.987857Z",
     "shell.execute_reply": "2023-06-28T02:20:35.986349Z"
    },
    "papermill": {
     "duration": 0.027109,
     "end_time": "2023-06-28T02:20:35.991050",
     "exception": false,
     "start_time": "2023-06-28T02:20:35.963941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Saving a Model\n",
    "# for q in quests_0_4 + quests_5_12 + quests_13_22:\n",
    "#     models[q].save_model(f'cat_model_{q}.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe97d5ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:36.025085Z",
     "iopub.status.busy": "2023-06-28T02:20:36.024608Z",
     "iopub.status.idle": "2023-06-28T02:20:36.033516Z",
     "shell.execute_reply": "2023-06-28T02:20:36.031166Z"
    },
    "papermill": {
     "duration": 0.029511,
     "end_time": "2023-06-28T02:20:36.036538",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.007027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Model Reading\n",
    "# dir = '/kaggle/input/catbust/'\n",
    "# for q in quests_0_4 + quests_5_12 + quests_13_22:\n",
    "#     models[q] = CatBoostClassifier().load_model(dir+f'cat_model_{q}.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed59f47",
   "metadata": {
    "papermill": {
     "duration": 0.015436,
     "end_time": "2023-06-28T02:20:36.068056",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.052620",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d19781a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:36.103222Z",
     "iopub.status.busy": "2023-06-28T02:20:36.101701Z",
     "iopub.status.idle": "2023-06-28T02:20:36.316201Z",
     "shell.execute_reply": "2023-06-28T02:20:36.314622Z"
    },
    "papermill": {
     "duration": 0.2357,
     "end_time": "2023-06-28T02:20:36.319729",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.084029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "import polars as pl\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1680f94f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:36.355198Z",
     "iopub.status.busy": "2023-06-28T02:20:36.354311Z",
     "iopub.status.idle": "2023-06-28T02:20:36.403469Z",
     "shell.execute_reply": "2023-06-28T02:20:36.402496Z"
    },
    "papermill": {
     "duration": 0.070931,
     "end_time": "2023-06-28T02:20:36.406607",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.335676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATS = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
    "NUMS = ['page', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y',\n",
    "        'hover_duration', 'elapsed_time_diff']\n",
    "\n",
    "DIALOGS = ['that', 'this', 'it', 'you','find','found','Found','notebook','Wells','wells','help','need', 'Oh','Ooh','Jo', 'flag', 'can','and','is','the','to']\n",
    "\n",
    "name_feature = ['basic', 'undefined', 'close', 'open', 'prev', 'next']\n",
    "event_name_feature = ['cutscene_click', 'person_click', 'navigate_click',\n",
    "       'observation_click', 'notification_click', 'object_click',\n",
    "       'object_hover', 'map_hover', 'map_click', 'checkpoint',\n",
    "       'notebook_click']\n",
    "\n",
    "fqid_lists = ['archivist', 'archivist_glasses', 'block', 'block_0', 'block_1', 'block_badge', 'block_badge_2', 'block_magnify', 'block_nelson', 'block_tocollection', 'block_tomap1', 'block_tomap2', 'boss', 'businesscards', 'businesscards.card_0.next', 'businesscards.card_1.next', 'businesscards.card_bingo.bingo', 'businesscards.card_bingo.next', 'ch3start', 'chap1_finale', 'chap1_finale_c', 'chap2_finale', 'chap2_finale_c', 'chap4_finale_c', 'coffee', 'colorbook', 'confrontation', 'crane_ranger', 'cs', 'directory', 'directory.closeup.archivist', 'door_block_clean', 'door_block_talk', 'doorblock', 'expert', 'flag_girl', 'fox', 'glasses', 'gramps', 'groupconvo', 'groupconvo_flag', 'intro', 'janitor', 'journals', 'journals.hub.topics', 'journals.pic_0.next', 'journals.pic_1.next', 'journals.pic_2.bingo', 'journals.pic_2.next', 'journals_flag', 'journals_flag.hub.topics', 'journals_flag.hub.topics_old', 'journals_flag.pic_0.bingo', 'journals_flag.pic_0.next', 'journals_flag.pic_0_old.next', 'journals_flag.pic_1.bingo', 'journals_flag.pic_1.next', 'journals_flag.pic_1_old.next', 'journals_flag.pic_2.bingo', 'journals_flag.pic_2.next', 'journals_flag.pic_2_old.next', 'key', 'lockeddoor', 'logbook', 'logbook.page.bingo', 'magnify', 'need_glasses', 'notebook', 'outtolunch', 'photo', 'plaque', 'plaque.face.date', 'reader', 'reader.paper0.next', 'reader.paper0.prev', 'reader.paper1.next', 'reader.paper1.prev', 'reader.paper2.bingo', 'reader.paper2.next', 'reader.paper2.prev', 'reader_flag', 'reader_flag.paper0.next', 'reader_flag.paper0.prev', 'reader_flag.paper1.next', 'reader_flag.paper1.prev', 'reader_flag.paper2.bingo', 'reader_flag.paper2.next', 'reader_flag.paper2.prev', 'remove_cup', 'report', 'retirement_letter', 'savedteddy', 'seescratches', 'teddy', 'tobasement', 'tocage', 'tocloset', 'tocloset_dirty', 'tocollection', 'tocollectionflag', 'toentry', 'tofrontdesk', 'togrampa', 'tohallway', 'tomap', 'tomicrofiche', 'tostacks', 'tracks', 'tracks.hub.deer', 'trigger_coffee', 'trigger_scarf', 'tunic', 'tunic.capitol_0', 'tunic.capitol_1', 'tunic.capitol_2', 'tunic.drycleaner', 'tunic.flaghouse', 'tunic.historicalsociety', 'tunic.hub.slip', 'tunic.humanecology', 'tunic.kohlcenter', 'tunic.library', 'tunic.wildlife', 'unlockdoor', 'wells', 'wellsbadge', 'what_happened', 'worker']\n",
    "text_lists = ['tunic.historicalsociety.cage.confrontation', 'tunic.wildlife.center.crane_ranger.crane', 'tunic.historicalsociety.frontdesk.archivist.newspaper', 'tunic.historicalsociety.entry.groupconvo', 'tunic.wildlife.center.wells.nodeer', 'tunic.historicalsociety.frontdesk.archivist.have_glass', 'tunic.drycleaner.frontdesk.worker.hub', 'tunic.historicalsociety.closet_dirty.gramps.news', 'tunic.humanecology.frontdesk.worker.intro', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation', 'tunic.historicalsociety.basement.seescratches', 'tunic.historicalsociety.collection.cs', 'tunic.flaghouse.entry.flag_girl.hello', 'tunic.historicalsociety.collection.gramps.found', 'tunic.historicalsociety.basement.ch3start', 'tunic.historicalsociety.entry.groupconvo_flag', 'tunic.library.frontdesk.worker.hello', 'tunic.library.frontdesk.worker.wells', 'tunic.historicalsociety.collection_flag.gramps.flag', 'tunic.historicalsociety.basement.savedteddy', 'tunic.library.frontdesk.worker.nelson', 'tunic.wildlife.center.expert.removed_cup', 'tunic.library.frontdesk.worker.flag', 'tunic.historicalsociety.frontdesk.archivist.hello', 'tunic.historicalsociety.closet.gramps.intro_0_cs_0', 'tunic.historicalsociety.entry.boss.flag', 'tunic.flaghouse.entry.flag_girl.symbol', 'tunic.historicalsociety.closet_dirty.trigger_scarf', 'tunic.drycleaner.frontdesk.worker.done', 'tunic.historicalsociety.closet_dirty.what_happened', 'tunic.wildlife.center.wells.animals', 'tunic.historicalsociety.closet.teddy.intro_0_cs_0', 'tunic.historicalsociety.cage.glasses.afterteddy', 'tunic.historicalsociety.cage.teddy.trapped', 'tunic.historicalsociety.cage.unlockdoor', 'tunic.historicalsociety.stacks.journals.pic_2.bingo', 'tunic.historicalsociety.entry.wells.flag', 'tunic.humanecology.frontdesk.worker.badger', 'tunic.historicalsociety.stacks.journals_flag.pic_0.bingo', 'tunic.historicalsociety.closet.intro', 'tunic.historicalsociety.closet.retirement_letter.hub', 'tunic.historicalsociety.entry.directory.closeup.archivist', 'tunic.historicalsociety.collection.tunic.slip', 'tunic.kohlcenter.halloffame.plaque.face.date', 'tunic.historicalsociety.closet_dirty.trigger_coffee', 'tunic.drycleaner.frontdesk.logbook.page.bingo', 'tunic.library.microfiche.reader.paper2.bingo', 'tunic.kohlcenter.halloffame.togrampa', 'tunic.capitol_2.hall.boss.haveyougotit', 'tunic.wildlife.center.wells.nodeer_recap', 'tunic.historicalsociety.cage.glasses.beforeteddy', 'tunic.historicalsociety.closet_dirty.gramps.helpclean', 'tunic.wildlife.center.expert.recap', 'tunic.historicalsociety.frontdesk.archivist.have_glass_recap', 'tunic.historicalsociety.stacks.journals_flag.pic_1.bingo', 'tunic.historicalsociety.cage.lockeddoor', 'tunic.historicalsociety.stacks.journals_flag.pic_2.bingo', 'tunic.historicalsociety.collection.gramps.lost', 'tunic.historicalsociety.closet.notebook', 'tunic.historicalsociety.frontdesk.magnify', 'tunic.humanecology.frontdesk.businesscards.card_bingo.bingo', 'tunic.wildlife.center.remove_cup', 'tunic.library.frontdesk.wellsbadge.hub', 'tunic.wildlife.center.tracks.hub.deer', 'tunic.historicalsociety.frontdesk.key', 'tunic.library.microfiche.reader_flag.paper2.bingo', 'tunic.flaghouse.entry.colorbook', 'tunic.wildlife.center.coffee', 'tunic.capitol_1.hall.boss.haveyougotit', 'tunic.historicalsociety.basement.janitor', 'tunic.historicalsociety.collection_flag.gramps.recap', 'tunic.wildlife.center.wells.animals2', 'tunic.flaghouse.entry.flag_girl.symbol_recap', 'tunic.historicalsociety.closet_dirty.photo', 'tunic.historicalsociety.stacks.outtolunch', 'tunic.library.frontdesk.worker.wells_recap', 'tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap', 'tunic.capitol_0.hall.boss.talktogramps', 'tunic.historicalsociety.closet.photo', 'tunic.historicalsociety.collection.tunic', 'tunic.historicalsociety.closet.teddy.intro_0_cs_5', 'tunic.historicalsociety.closet_dirty.gramps.archivist', 'tunic.historicalsociety.closet_dirty.door_block_talk', 'tunic.historicalsociety.entry.boss.flag_recap', 'tunic.historicalsociety.frontdesk.archivist.need_glass_0', 'tunic.historicalsociety.entry.wells.talktogramps', 'tunic.historicalsociety.frontdesk.block_magnify', 'tunic.historicalsociety.frontdesk.archivist.foundtheodora', 'tunic.historicalsociety.closet_dirty.gramps.nothing', 'tunic.historicalsociety.closet_dirty.door_block_clean', 'tunic.capitol_1.hall.boss.writeitup', 'tunic.library.frontdesk.worker.nelson_recap', 'tunic.library.frontdesk.worker.hello_short', 'tunic.historicalsociety.stacks.block', 'tunic.historicalsociety.frontdesk.archivist.need_glass_1', 'tunic.historicalsociety.entry.boss.talktogramps', 'tunic.historicalsociety.frontdesk.archivist.newspaper_recap', 'tunic.historicalsociety.entry.wells.flag_recap', 'tunic.drycleaner.frontdesk.worker.done2', 'tunic.library.frontdesk.worker.flag_recap', 'tunic.humanecology.frontdesk.block_0', 'tunic.library.frontdesk.worker.preflag', 'tunic.historicalsociety.basement.gramps.seeyalater', 'tunic.flaghouse.entry.flag_girl.hello_recap', 'tunic.historicalsociety.closet.doorblock', 'tunic.drycleaner.frontdesk.worker.takealook', 'tunic.historicalsociety.basement.gramps.whatdo', 'tunic.library.frontdesk.worker.droppedbadge', 'tunic.historicalsociety.entry.block_tomap2', 'tunic.library.frontdesk.block_nelson', 'tunic.library.microfiche.block_0', 'tunic.historicalsociety.entry.block_tocollection', 'tunic.historicalsociety.entry.block_tomap1', 'tunic.historicalsociety.collection.gramps.look_0', 'tunic.library.frontdesk.block_badge', 'tunic.historicalsociety.cage.need_glasses', 'tunic.library.frontdesk.block_badge_2', 'tunic.kohlcenter.halloffame.block_0', 'tunic.capitol_0.hall.chap1_finale_c', 'tunic.capitol_1.hall.chap2_finale_c', 'tunic.capitol_2.hall.chap4_finale_c', 'tunic.wildlife.center.fox.concern', 'tunic.drycleaner.frontdesk.block_0', 'tunic.historicalsociety.entry.gramps.hub', 'tunic.humanecology.frontdesk.block_1', 'tunic.drycleaner.frontdesk.block_1']\n",
    "room_lists = ['tunic.historicalsociety.entry', 'tunic.wildlife.center', 'tunic.historicalsociety.cage', 'tunic.library.frontdesk', 'tunic.historicalsociety.frontdesk', 'tunic.historicalsociety.stacks', 'tunic.historicalsociety.closet_dirty', 'tunic.humanecology.frontdesk', 'tunic.historicalsociety.basement', 'tunic.kohlcenter.halloffame', 'tunic.library.microfiche', 'tunic.drycleaner.frontdesk', 'tunic.historicalsociety.collection', 'tunic.historicalsociety.closet', 'tunic.flaghouse.entry', 'tunic.historicalsociety.collection_flag', 'tunic.capitol_1.hall', 'tunic.capitol_0.hall', 'tunic.capitol_2.hall']\n",
    "\n",
    "LEVELS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
    "level_groups = [\"0-4\", \"5-12\", \"13-22\"]\n",
    "\n",
    "# best_F1_scores: 0.700135261005169, best_threshold_xgbs: 0.6250000000000002, best_feature_selection: [\"Well, that's good enough for me.\", 'So? History is boring!', \"Why don't you head to the Basketball Center and rustle up some clues?\", 'Yes! This old slip from 1916.', \"The slip is from 1916 but the team didn't start until 1974!\", 'We need to talk about that missing paperwork.', \"I feel like I'm forgetting something.\", 'Ooh, I like clues!', \"It's already all done!\", \"Hey Jo, let's take a look at the shirt!\", 'I should go talk to Gramps!', \"Hmmm. Shouldn't you be doing your homework?\", 'Our shirt is too old to be a basketball jersey!', 'Your teacher said you missed 7 assignments in a row!', \"This can't be right!\", 'Find anything?', 'See?', 'Gramps is in trouble for losing papers?', 'Then do it for me!', 'Will do, Boss.', 'Plus, my teacher said I could help you out for extra credit!', 'Yes! This cool old slip from 1916.', 'Found it!', 'Your teacher said you could help me for extra credit.', 'Teddy and I were gonna go climb that huge tree out back!', 'Sure thing, Jo. Grab your notebook and come upstairs!', 'Whatcha doing over there, Jo?', \"Let's get started. The Wisconsin Wonders exhibit opens tomorrow!\", \"Meet me back in my office and we'll get started!\", 'Wells, finish up your report.', 'Sure!', 'See you later, Teddy.', 'A boring old shirt.', 'Meetings are BORING!', 'Now where did I put my notebook?', 'Ugh. Meetings are so boring.', 'Did you do all of them?', \"I'll record this in my notebook.\", 'Gramps is the best historian ever!', \"I get to go to Gramps's meeting!\", \"Why don't you go play with your grampa?\", 'I love these photos of me and Teddy!', \"Why don't you go catch up with your grampa?\", 'I suppose historians are boring, too?', 'Head over to the Basketball Center.', 'Can I come, Gramps?', 'Better check back later.', \"Leopold, why don't you help me set up in the Capitol?\", 'I gotta run to my meeting!', 'Just talking to Teddy.', 'Just this old slip from 1916.', '\\\\u00f0\\\\u0178\\\\u02dc\\\\u00b4', 'Gramps said to look for clues. Better look around.', \"I'll be at the Capitol. Let me know if you find anything!\", 'I should see what Grampa is up to!', 'Hooray, a boring old shirt.', 'Grab your notebook and come upstairs!', 'I need to get to the Capitol and tell Gramps!', \"It's a women's basketball jersey!\", 'What a fascinating artifact!', \"Not Leopold here. He's been losing papers lately.\", \"Wow, that's so cool, Gramps!\", 'Hot Dog! I knew it!', 'Have a look at the artifact!', \"Hmmm. Don't forget about your homework.\", 'No... because history is boring!', 'Do I have to?', 'Hey!', \"Well, I did SOME of those. I just couldn't find them!\", 'Hang tight, Teddy.', 'Besides, I already figured out the shirt.', 'Wait, you mean Wells is wrong?!', 'I should see what Gramps is up to!', \"That's it!\", 'Can we hurry up, Gramps?', \"Look at that! It's the bee's knees!\", \"No way, Gramps. You're the best!\", 'Gramps is a great historian!', 'Who wants to investigate the shirt artifact?', \"Hmm. Button's still not working.\", \"It's true, they do keep going missing lately.\", 'Your grampa is waiting for you in the collection room.', 'Go ahead, take a peek at the shirt!', 'Could be. But we need evidence!', \"I'll hurry back and then we can go exploring!\", 'Well, Leopold here is always losing papers...', 'This button never works!', 'Come on, Jo!', 'I knew it!', 'This looks like a clue!', 'Hopefully you can rustle up some clues!', 'That settles it.', 'Hopefully you can find some clues!', 'Can I take a closer look?', \"I'm not so sure that this is a basketball jersey.\", 'Ha. Told you so!']\n",
    "level1_text_lists = [\"Well, that's good enough for me.\", 'So? History is boring!', \"Why don't you head to the Basketball Center and rustle up some clues?\", 'Yes! This old slip from 1916.', \"The slip is from 1916 but the team didn't start until 1974!\", 'We need to talk about that missing paperwork.', \"I feel like I'm forgetting something.\", 'Ooh, I like clues!', \"It's already all done!\", \"Hey Jo, let's take a look at the shirt!\", 'I should go talk to Gramps!', \"Hmmm. Shouldn't you be doing your homework?\", 'Our shirt is too old to be a basketball jersey!', 'Your teacher said you missed 7 assignments in a row!', \"This can't be right!\", 'Find anything?', 'See?', 'Gramps is in trouble for losing papers?', 'Then do it for me!', 'Will do, Boss.', 'Plus, my teacher said I could help you out for extra credit!', 'Yes! This cool old slip from 1916.', 'Found it!', 'Your teacher said you could help me for extra credit.', 'Teddy and I were gonna go climb that huge tree out back!', 'Sure thing, Jo. Grab your notebook and come upstairs!', 'Whatcha doing over there, Jo?', \"Let's get started. The Wisconsin Wonders exhibit opens tomorrow!\", \"Meet me back in my office and we'll get started!\", 'Wells, finish up your report.', 'Sure!', 'See you later, Teddy.', 'A boring old shirt.', 'Meetings are BORING!', 'Now where did I put my notebook?', 'Ugh. Meetings are so boring.', 'Did you do all of them?', \"I'll record this in my notebook.\", 'Gramps is the best historian ever!', \"I get to go to Gramps's meeting!\", \"Why don't you go play with your grampa?\", 'I love these photos of me and Teddy!', \"Why don't you go catch up with your grampa?\", 'I suppose historians are boring, too?', 'Head over to the Basketball Center.', 'Can I come, Gramps?', 'Better check back later.', \"Leopold, why don't you help me set up in the Capitol?\", 'I gotta run to my meeting!', 'Just talking to Teddy.', 'Just this old slip from 1916.', '\\\\u00f0\\\\u0178\\\\u02dc\\\\u00b4', 'Gramps said to look for clues. Better look around.', \"I'll be at the Capitol. Let me know if you find anything!\", 'I should see what Grampa is up to!', 'Hooray, a boring old shirt.', 'Grab your notebook and come upstairs!', 'I need to get to the Capitol and tell Gramps!', \"It's a women's basketball jersey!\", 'What a fascinating artifact!', \"Not Leopold here. He's been losing papers lately.\", \"Wow, that's so cool, Gramps!\", 'Hot Dog! I knew it!', 'Have a look at the artifact!', \"Hmmm. Don't forget about your homework.\", 'No... because history is boring!', 'Do I have to?', 'Hey!', \"Well, I did SOME of those. I just couldn't find them!\", 'Hang tight, Teddy.', 'Besides, I already figured out the shirt.', 'Wait, you mean Wells is wrong?!', 'I should see what Gramps is up to!', \"That's it!\", 'Can we hurry up, Gramps?', \"Look at that! It's the bee's knees!\", \"No way, Gramps. You're the best!\", 'Gramps is a great historian!', 'Who wants to investigate the shirt artifact?', \"Hmm. Button's still not working.\", \"It's true, they do keep going missing lately.\", 'Your grampa is waiting for you in the collection room.', 'Go ahead, take a peek at the shirt!', 'Could be. But we need evidence!', \"I'll hurry back and then we can go exploring!\", 'Well, Leopold here is always losing papers...', 'This button never works!', 'Come on, Jo!', 'I knew it!', 'This looks like a clue!', 'Hopefully you can rustle up some clues!', 'That settles it.', 'Hopefully you can find some clues!', 'Can I take a closer look?', \"I'm not so sure that this is a basketball jersey.\", 'Ha. Told you so!']\n",
    "\n",
    "# level2_text_lists = ['*COUGH COUGH COUGH*', '*cough cough*', '*grumble grumble*', 'A little horse!', 'AND I know who took Teddy!', 'AND he stole Teddy!', \"Ah, that's better!\", 'An old shirt? Try the university.', \"And I'll figure out the shirt, too.\", \"And he messed up Gramps's office, too!\", \"And look! She's wearing the shirt!\", \"And where's your grampa?\", 'And you are?', 'Are you okay?', 'BUT WELLS STOLE TEDDY!', 'Badgers? No.', 'Better check back later.', \"But I hear the museum's got one on the loose!\", 'But he never goes anywhere without his scarf!', 'But what if Wells kidnapped Teddy?', \"Calm down, kid. I haven't seen him.\", 'Can I give you the tour?', 'Can you help me find Wells?', 'Can you help me tidy up?', 'Can you help me-', 'Can you help me? I need to find Wells!', 'Can you help me? I need to find the owner of this slip.', 'Can you help-', \"Can't believe I lost my reading glasses.\", \"Check out our microfiche. It's right through that door.\", 'Could be. But we need evidence.', 'Did you drop something, Dear?', \"Did you drop something, Dear? There's a card on the floor.\", 'Did you figure out the shirt?', 'Did you have a question or not?', 'Did you have a question?', 'Do you have any info on Theodora Youmans?', 'Do you know anything about this slip?', 'Do you know what this slip is?', 'Do you know who Theodora Youmans is?', \"Don't worry, Gramps. I'll find Teddy!\", 'Easy, Jo.', \"Fine. Let's investigate!\", 'Go find your grampa and get to work!', 'Great! Thanks for the help!', \"Guess it couldn't hurt to let you take a look.\", 'Ha! Good one.', 'Ha! What do you call a pony with a sore throat?', \"Ha! You're funny.\", 'Have you seen a badger around here?', 'He needs our help!', 'He was looking for a taxidermist.', \"He's always trying to get you in trouble, and he doesn't like animals!\", \"He's our expert record keeper.\", \"He's wrong about old shirts and his name rhymes with \\\\smells\\\\...\", 'Head over to the university.', 'Head upstairs and talk to the archivist. He might be able to help!', 'Hello there!', 'Here I am!', \"Here's a call number to find more info in the Stacks.\", \"Here's the log book.\", 'Hey, this is Youmans!', 'Hi! *cough*', 'Hi! How can I help you?', 'Hi, Mrs. M.', \"Hmm. Button's still not working.\", \"Hmmm... not sure. Why don't you try the library?\", 'Hold your horses, Jo.', 'How can I help you?', 'Huh?', 'I bet the archivist could use this!', \"I can't calm down. This is important!\", \"I don't have time for kids.\", \"I don't know!\", \"I don't need that right now.\", 'I figured out that you kidnapped him!', 'I found it on an old shirt.', 'I found it!', 'I got here and the whole place was a mess!', 'I got here and the whole place was ransacked!', 'I got that one from my Gramps!', 'I had some cleaning up to do in my office.', 'I have an idea.', \"I haven't quite figured it out just yet...\", \"I haven't seen him.\", 'I hope you find your badger, kid.', 'I knew I could count on you, Jo!', 'I knew you could do it, Jo!', 'I love these photos of me and Teddy.', 'I need to find Wells right away! Do you know where he is?', 'I need to find Wells right away!! Do you know where he is?', 'I need to find Wells!!!', 'I need to find the owner of this slip.', 'I need your help!', 'I ran into Wells there this morning.', 'I should ask the librarian why Wells was here.', 'I should check that logbook to see who owned this slip...', 'I should find out if she can help me!', 'I should go to the Capitol and tell everyone!', 'I should help Gramps clean.', 'I should stay and look for clues!', \"I think he's in trouble!\", 'I used to have a magnifying glass around here\\\\u00e2\\\\u20ac\\\\u00a6', \"I wonder if there's a clue in those business cards...\", \"I'm Leopold's grandkid!\", \"I'm afraid my papers have gone missing in this mess.\", \"I'm afraid not.\", \"I'm also looking for Theodora Youmans. Have you heard of her?\", \"I'm sure you'll find Theodora in there somewhere!\", \"I've got a stack of business cards from my favorite cleaners.\", 'Is this your coffee, Gramps?', \"It must've been Wells.\", \"It'll be okay, Jo. We'll find Teddy!\", \"It's a match!\", \"It's for Grampa Leo. He's a historian!\", \"It's our Norwegian Craft exhibit!\", \"It's such a nice fall day.\", 'Jo, meet me back at my office.', \"Jolie! I was hoping you'd stop by. Any news on the shirt artifact?\", 'Knew what?', 'Leo... you mean Leopold?', 'Leopold, can you run back to the museum?', 'Looks like a dry cleaning receipt.', 'Maybe I can help!', 'Maybe he just got scared and ran off.', \"Maybe there's a clue in this mess!\", 'Mrs. M, I think Wells kidnapped Teddy.', 'Nice decorations.', 'Nice seeing you, Jolie!', 'Nice work on the shirt, Jolie!', \"Nope, that's from Bean Town. I only drink Holdgers!\", 'Nope. But Youmans and other suffragists worked hard to change that.', 'Not sure. Here, let me look it up.', 'Now I Just need to find all the cleaners from way back in 1916.', 'Now I just need to find all the cleaners from wayyyy back in 1916.', 'Now can I tell you what happened to Teddy?', 'Now if only I could read this thing.', 'Now if only I could read this thing. Blasted tiny letters...', 'Oh my!', 'Oh no!', 'Oh no... Teddy!', \"Oh, I'm fine! Just a little hoarse.\", 'Oh, hello there!', \"Oh, that's from Bean Town.\", \"Okay. I'll find Teddy!\", 'Okay. Thanks anyway.', 'One step at a time, Jo.', 'Ooh, nice decorations!', 'Ooh, thanks!', 'Please let me know if you do.', \"Please let me know if you do. It's important!\", 'Please?', 'Please? This is really important.', \"Poor Gramps! I should make sure he's okay.\", 'Right outside the door.', 'Run along to the university.', 'She helped get votes for women!', 'She led marches and helped women get the right to vote!', 'Slow down, Jo.', 'So much cleaning to do...', \"Sorry I'm late.\", 'Sorry for the delay, Boss.', \"Sorry, I'm in a hurry.\", \"Sorry, I'm too busy for kids right now.\", \"Sorry, can't help you.\", 'Sounds good, Boss.', 'Take a look!', \"Teddy's scarf! Somebody must've taken him!\", 'Thanks for the help!', 'Thanks to them, Wisconsin was the first state to approve votes for women!', 'Thanks.', 'Thanks. Did you figure out the shirt?', 'The archivist said I should look in the stacks.', 'The libarian said I could find some information on Youmans in here...', 'Then we need evidence.', 'Theodora Youmans must be the owner!', 'Theodora Youmans? Is that who owned the shirt?', 'Theodora Youmans? Of course!', 'Theodora wearing the shirt!', 'They study clothes and fabric.', 'This button never works!', 'This place was around in 1916! I can start there!', 'Try not to panic, Jo.', 'Two missions, actually!', 'Ugh. Fine.', 'Um, are you okay?', \"Unless you're too busy horsing around.\", 'Wait a minute!', \"Wait a sec. Women couldn't vote?!\", 'Welcome back, Jolie. Did you figure out the shirt?', \"Well, I can't show our log books to just anybody.\", \"Well, get on it. I'm counting on you and your gramps to figure this out!\", 'Well? What are you still doing here?', 'Wells sabotaged Gramps!', 'Wells! What was he doing here? I should ask the librarian.', \"Wells! Where's Teddy? Is he okay?\", 'Wells? I knew it!', \"Weren't you going to check out our microfiche?\", 'What are you still doing here,  Jolie?', 'What are you waiting for? The Stacks are right outside the door.', 'What happened here?!', 'What should I do first?', 'What the-', 'What was Wells doing here?', \"What's a taxidermist?\", \"What's a textile expert?\", 'Where are the Stacks?', 'Where did you get that coffee?', 'Where should I go again?', 'Who are you?', \"Who could've done this?\", 'Who is Teddy?', \"Why didn't you say so?\", \"Why don't you go upstairs and see the archivist?\", \"Why don't you prove your case?\", \"Why don't you take a look?\", 'Wow!', 'Wow! What is all this stuff?', 'Yeah. Thanks anyway.', 'Yep.', 'Yes!', 'Yes! I was wondering-', 'Yikes... this could take a while.', 'You better get to the capitol!', 'You can talk to a textile expert there.', 'You could ask the archivist. He knows everybody!', 'You could try the archivist. Maybe he can help you find Wells!', \"You haven't seen any badgers around here, have you?\", \"You look like you're on a mission.\", \"You'll have to get started without me.\", \"You're right, Gramps. Let's investigate!\", \"You're still here? I'm trying to work!\", 'Youmans was a suffragist here in Wisconsin.', 'Youmans was a suffragist!', 'Your gramps is awesome! Always full of stories.', \"Yup, that's him!\", '\\\\Taxidermy: the art of preparing, stuffing, and mounting the skins of animals.\\\\']\n",
    "level2_text_lists = ['*COUGH COUGH COUGH*', '*cough cough*', '*grumble grumble*', 'A little horse!', 'AND I know who took Teddy!', 'AND he stole Teddy!', \"Ah, that's better!\", 'An old shirt? Try the university.', \"And I'll figure out the shirt, too.\", \"And he messed up Gramps's office, too!\", \"And look! She's wearing the shirt!\", \"And where's your grampa?\", 'And you are?', 'Are you okay?', 'BUT WELLS STOLE TEDDY!', 'Badgers? No.', 'Better check back later.', \"But I hear the museum's got one on the loose!\", 'But he never goes anywhere without his scarf!', 'But what if Wells kidnapped Teddy?', \"Calm down, kid. I haven't seen him.\", 'Can I give you the tour?', 'Can you help me find Wells?', 'Can you help me tidy up?', 'Can you help me-', 'Can you help me? I need to find Wells!', 'Can you help me? I need to find the owner of this slip.', 'Can you help-', \"Can't believe I lost my reading glasses.\", \"Check out our microfiche. It's right through that door.\", 'Could be. But we need evidence.', 'Did you drop something, Dear?', \"Did you drop something, Dear? There's a card on the floor.\", 'Did you figure out the shirt?', 'Did you have a question or not?', 'Did you have a question?', 'Do you have any info on Theodora Youmans?', 'Do you know anything about this slip?', 'Do you know what this slip is?', 'Do you know who Theodora Youmans is?', \"Don't worry, Gramps. I'll find Teddy!\", 'Easy, Jo.', \"Fine. Let's investigate!\", 'Go find your grampa and get to work!', 'Great! Thanks for the help!', \"Guess it couldn't hurt to let you take a look.\", 'Ha! Good one.', 'Ha! What do you call a pony with a sore throat?', \"Ha! You're funny.\", 'Have you seen a badger around here?', 'He needs our help!', 'He was looking for a taxidermist.', \"He's always trying to get you in trouble, and he doesn't like animals!\", \"He's our expert record keeper.\", \"He's wrong about old shirts and his name rhymes with \\\\smells\\\\...\", 'Head over to the university.', 'Head upstairs and talk to the archivist. He might be able to help!', 'Hello there!', 'Here I am!', \"Here's a call number to find more info in the Stacks.\", \"Here's the log book.\", 'Hey, this is Youmans!', 'Hi! *cough*', 'Hi! How can I help you?', 'Hi, Mrs. M.', \"Hmm. Button's still not working.\", \"Hmmm... not sure. Why don't you try the library?\", 'Hold your horses, Jo.', 'How can I help you?', 'Huh?', 'I bet the archivist could use this!', \"I can't calm down. This is important!\", \"I don't have time for kids.\", \"I don't know!\", \"I don't need that right now.\", 'I figured out that you kidnapped him!', 'I found it on an old shirt.', 'I found it!', 'I got here and the whole place was a mess!', 'I got here and the whole place was ransacked!', 'I got that one from my Gramps!', 'I had some cleaning up to do in my office.', 'I have an idea.', \"I haven't quite figured it out just yet...\", \"I haven't seen him.\", 'I hope you find your badger, kid.', 'I knew I could count on you, Jo!', 'I knew you could do it, Jo!', 'I love these photos of me and Teddy.', 'I need to find Wells right away! Do you know where he is?', 'I need to find Wells right away!! Do you know where he is?', 'I need to find Wells!!!', 'I need to find the owner of this slip.', 'I need your help!', 'I ran into Wells there this morning.', 'I should ask the librarian why Wells was here.', 'I should check that logbook to see who owned this slip...', 'I should find out if she can help me!', 'I should go to the Capitol and tell everyone!', 'I should help Gramps clean.', 'I should stay and look for clues!', \"I think he's in trouble!\", 'I used to have a magnifying glass around here\\\\u00e2\\\\u20ac\\\\u00a6', \"I wonder if there's a clue in those business cards...\", \"I'm Leopold's grandkid!\", \"I'm afraid my papers have gone missing in this mess.\", \"I'm afraid not.\", \"I'm also looking for Theodora Youmans. Have you heard of her?\", \"I'm sure you'll find Theodora in there somewhere!\", \"I've got a stack of business cards from my favorite cleaners.\", 'Is this your coffee, Gramps?', \"It must've been Wells.\", \"It'll be okay, Jo. We'll find Teddy!\", \"It's a match!\", \"It's for Grampa Leo. He's a historian!\", \"It's our Norwegian Craft exhibit!\", \"It's such a nice fall day.\", 'Jo, meet me back at my office.', \"Jolie! I was hoping you'd stop by. Any news on the shirt artifact?\", 'Knew what?', 'Leo... you mean Leopold?', 'Leopold, can you run back to the museum?', 'Looks like a dry cleaning receipt.', 'Maybe I can help!', 'Maybe he just got scared and ran off.', \"Maybe there's a clue in this mess!\", 'Mrs. M, I think Wells kidnapped Teddy.', 'Nice decorations.', 'Nice seeing you, Jolie!', 'Nice work on the shirt, Jolie!', \"Nope, that's from Bean Town. I only drink Holdgers!\", 'Nope. But Youmans and other suffragists worked hard to change that.', 'Not sure. Here, let me look it up.', 'Now I Just need to find all the cleaners from way back in 1916.', 'Now I just need to find all the cleaners from wayyyy back in 1916.', 'Now can I tell you what happened to Teddy?', 'Now if only I could read this thing.', 'Now if only I could read this thing. Blasted tiny letters...', 'Oh my!', 'Oh no!', 'Oh no... Teddy!', \"Oh, I'm fine! Just a little hoarse.\", 'Oh, hello there!', \"Oh, that's from Bean Town.\", \"Okay. I'll find Teddy!\", 'Okay. Thanks anyway.', 'One step at a time, Jo.', 'Ooh, nice decorations!', 'Ooh, thanks!', 'Please let me know if you do.', \"Please let me know if you do. It's important!\", 'Please?', 'Please? This is really important.', \"Poor Gramps! I should make sure he's okay.\", 'Right outside the door.', 'Run along to the university.', 'She helped get votes for women!', 'She led marches and helped women get the right to vote!', 'Slow down, Jo.', 'So much cleaning to do...', \"Sorry I'm late.\", 'Sorry for the delay, Boss.', \"Sorry, I'm in a hurry.\", \"Sorry, I'm too busy for kids right now.\", \"Sorry, can't help you.\", 'Sounds good, Boss.', 'Take a look!', \"Teddy's scarf! Somebody must've taken him!\", 'Thanks for the help!', 'Thanks to them, Wisconsin was the first state to approve votes for women!', 'Thanks.', 'Thanks. Did you figure out the shirt?', 'The archivist said I should look in the stacks.', 'The libarian said I could find some information on Youmans in here...', 'Then we need evidence.', 'Theodora Youmans must be the owner!', 'Theodora Youmans? Is that who owned the shirt?', 'Theodora Youmans? Of course!', 'Theodora wearing the shirt!', 'They study clothes and fabric.', 'This button never works!', 'This place was around in 1916! I can start there!', 'Try not to panic, Jo.', 'Two missions, actually!', 'Ugh. Fine.', 'Um, are you okay?', \"Unless you're too busy horsing around.\", 'Wait a minute!', \"Wait a sec. Women couldn't vote?!\", 'Welcome back, Jolie. Did you figure out the shirt?', \"Well, I can't show our log books to just anybody.\", \"Well, get on it. I'm counting on you and your gramps to figure this out!\", 'Well? What are you still doing here?', 'Wells sabotaged Gramps!', 'Wells! What was he doing here? I should ask the librarian.', \"Wells! Where's Teddy? Is he okay?\", 'Wells? I knew it!', \"Weren't you going to check out our microfiche?\", 'What are you still doing here,  Jolie?', 'What are you waiting for? The Stacks are right outside the door.', 'What happened here?!', 'What should I do first?', 'What the-', 'What was Wells doing here?', \"What's a taxidermist?\", \"What's a textile expert?\", 'Where are the Stacks?', 'Where did you get that coffee?', 'Where should I go again?', 'Who are you?', \"Who could've done this?\", 'Who is Teddy?', \"Why didn't you say so?\", \"Why don't you go upstairs and see the archivist?\", \"Why don't you prove your case?\", \"Why don't you take a look?\", 'Wow!', 'Wow! What is all this stuff?', 'Yeah. Thanks anyway.', 'Yep.', 'Yes!', 'Yes! I was wondering-', 'Yikes... this could take a while.', 'You better get to the capitol!', 'You can talk to a textile expert there.', 'You could ask the archivist. He knows everybody!', 'You could try the archivist. Maybe he can help you find Wells!', \"You haven't seen any badgers around here, have you?\", \"You look like you're on a mission.\", \"You'll have to get started without me.\", \"You're right, Gramps. Let's investigate!\", \"You're still here? I'm trying to work!\", 'Youmans was a suffragist here in Wisconsin.', 'Youmans was a suffragist!', 'Your gramps is awesome! Always full of stories.', \"Yup, that's him!\", '\\\\Taxidermy: the art of preparing, stuffing, and mounting the skins of animals.\\\\']\n",
    "\n",
    "\n",
    "PAGES = [0, 1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86b50396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:36.444049Z",
     "iopub.status.busy": "2023-06-28T02:20:36.443074Z",
     "iopub.status.idle": "2023-06-28T02:20:36.514500Z",
     "shell.execute_reply": "2023-06-28T02:20:36.513526Z"
    },
    "papermill": {
     "duration": 0.093775,
     "end_time": "2023-06-28T02:20:36.517540",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.423765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer_xgboost(x, grp, use_extra, feature_suffix):\n",
    "    aggs = [\n",
    "        pl.col(\"index\").count().alias(f\"session_number_{feature_suffix}\"),        \n",
    "        \n",
    "        *[pl.col(c).drop_nulls().n_unique().alias(f\"{c}_unique_{feature_suffix}\") for c in CATS],\n",
    "\n",
    "        *[pl.col(c).mean().alias(f\"{c}_mean_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).std().alias(f\"{c}_std_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).min().alias(f\"{c}_min_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).median().alias(f\"{c}_median_{feature_suffix}\") for c in NUMS],\n",
    "        \n",
    "        *[pl.col(c).quantile(0.1, \"nearest\").alias(f\"{c}_quantile1_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.2, \"nearest\").alias(f\"{c}_quantile2_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.4, \"nearest\").alias(f\"{c}_quantile4_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.6, \"nearest\").alias(f\"{c}_quantile6_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.8, \"nearest\").alias(f\"{c}_quantile8_{feature_suffix}\") for c in NUMS],\n",
    "        *[pl.col(c).quantile(0.9, \"nearest\").alias(f\"{c}_quantile9_{feature_suffix}\") for c in NUMS],\n",
    "        \n",
    "        \n",
    "\n",
    "        *[pl.col(\"fqid\").filter(pl.col(\"fqid\") == c).count().alias(f\"{c}_fqid_counts{feature_suffix}\") for c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for c in fqid_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in fqid_lists],\n",
    "\n",
    "        *[pl.col(\"text_fqid\").filter(pl.col(\"text_fqid\") == c).count().alias(f\"{c}_text_fqid_counts{feature_suffix}\") for c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for c in text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in text_lists],\n",
    "\n",
    "        *[pl.col(\"room_fqid\").filter(pl.col(\"room_fqid\") == c).count().alias(f\"{c}_room_fqid_counts{feature_suffix}\")\n",
    "          for c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\")\n",
    "          for\n",
    "          c in room_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in room_lists],\n",
    "        \n",
    "        \n",
    "\n",
    "        *[pl.col(\"event_name\").filter(pl.col(\"event_name\") == c).count().alias(f\"{c}_event_name_counts{feature_suffix}\")\n",
    "          for c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\")\n",
    "          for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).median().alias(\n",
    "            f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"event_name\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in event_name_feature],\n",
    "\n",
    "        *[pl.col(\"name\").filter(pl.col(\"name\") == c).count().alias(f\"{c}_name_counts{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in\n",
    "          name_feature],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"name\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in\n",
    "          name_feature],\n",
    "\n",
    "        *[pl.col(\"level\").filter(pl.col(\"level\") == c).count().alias(f\"{c}_LEVEL_count{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\") for c\n",
    "          in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).median().alias(f\"{c}_ET_median_{feature_suffix}\") for\n",
    "          c in\n",
    "          LEVELS],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for c in\n",
    "          LEVELS],\n",
    "        \n",
    "        *[pl.col(\"page\").filter(pl.col(\"page\") == c).count().alias(f\"{c}_page_count{feature_suffix}\") for c in\n",
    "          PAGES],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"page\") == c).std().alias(f\"{c}_page_std_{feature_suffix}\") for c in\n",
    "          PAGES],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"page\") == c).mean().alias(f\"{c}_page_mean_{feature_suffix}\") for c\n",
    "          in PAGES],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"page\") == c).sum().alias(f\"{c}_page_sum_{feature_suffix}\") for c in\n",
    "          PAGES],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"page\") == c).median().alias(f\"{c}_page_median_{feature_suffix}\") for\n",
    "          c in PAGES],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"page\") == c).max().alias(f\"{c}_page_max_{feature_suffix}\") for c in\n",
    "          PAGES],\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        *[pl.col(\"level_group\").filter(pl.col(\"level_group\") == c).count().alias(\n",
    "            f\"{c}_LEVEL_group_count{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).std().alias(f\"{c}_ET_std_{feature_suffix}\") for\n",
    "          c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).mean().alias(f\"{c}_ET_mean_{feature_suffix}\")\n",
    "          for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).sum().alias(f\"{c}_ET_sum_{feature_suffix}\") for\n",
    "          c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).median().alias(\n",
    "            f\"{c}_ET_median_{feature_suffix}\") for c in\n",
    "          level_groups],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"level_group\") == c).max().alias(f\"{c}_ET_max_{feature_suffix}\") for\n",
    "          c in\n",
    "          level_groups],\n",
    "        \n",
    "        \n",
    "        *[pl.col(\"text\").filter(pl.col(\"text\") == c).count().alias(f\"{c}_level1_text_counts{feature_suffix}\") for c in level1_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).std().alias(f\"{c}_level1_text_ET_std_{feature_suffix}\") for c in level1_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).mean().alias(f\"{c}_level1_text_ET_mean_{feature_suffix}\") for c in level1_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).sum().alias(f\"{c}_level1_text_ET_sum_{feature_suffix}\") for c in level1_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).median().alias(f\"{c}_level1_text_ET_median_{feature_suffix}\") for c in level1_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).max().alias(f\"{c}_level1_text_ET_max_{feature_suffix}\") for c in level1_text_lists],\n",
    "        \n",
    "        \n",
    "        *[pl.col(\"text\").filter(pl.col(\"text\") == c).count().alias(f\"{c}_level2_text_counts{feature_suffix}\") for c in level2_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).std().alias(f\"{c}_level2_text_ET_std_{feature_suffix}\") for c in level2_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).mean().alias(f\"{c}_level2_text_ET_mean_{feature_suffix}\") for c in level2_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).sum().alias(f\"{c}_level2_text_ET_sum_{feature_suffix}\") for c in level2_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).median().alias(f\"{c}_level2_text_ET_median_{feature_suffix}\") for c in level2_text_lists],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).max().alias(f\"{c}_level2_text_ET_max_{feature_suffix}\") for c in level2_text_lists],\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    ]\n",
    "\n",
    "    df = x.groupby(['session_id'], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "\n",
    "    if use_extra:\n",
    "        if grp == '5-12':\n",
    "            aggs = [\n",
    "                pl.col(\"elapsed_time\").filter((pl.col(\"text\") == \"Here's the log book.\")\n",
    "                                              | (pl.col(\"fqid\") == 'logbook.page.bingo'))\n",
    "                    .apply(lambda s: s.max() - s.min()).alias(\"logbook_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    (pl.col(\"text\") == \"Here's the log book.\") | (pl.col(\"fqid\") == 'logbook.page.bingo')).apply(\n",
    "                    lambda s: s.max() - s.min()).alias(\"logbook_bingo_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (\n",
    "                            pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"reader_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader')) | (\n",
    "                        pl.col(\"fqid\") == \"reader.paper2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"reader_bingo_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (\n",
    "                            pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"journals_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals')) | (\n",
    "                        pl.col(\"fqid\") == \"journals.pic_2.bingo\")).apply(lambda s: s.max() - s.min()).alias(\n",
    "                    \"journals_bingo_indexCount\"),\n",
    "                \n",
    "                \n",
    "               (pl.col('index').filter((pl.col('fqid')=='logbook.page.bingo') & (pl.col('event_name')=='object_click')).first() - pl.col('index').filter((pl.col('fqid')=='logbook')).first()).alias('logbingo-logbook_first'), # Not Working\n",
    "               \n",
    "            ]            \n",
    "                \n",
    "#             # logbook first feature (index, elapsed_time)                            \n",
    "\n",
    "            \n",
    "            \n",
    "            tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "            df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "        if grp == '13-22':\n",
    "            aggs = [\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'reader_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"tunic.library.microfiche.reader_flag.paper2.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"reader_flag_indexCount\"),\n",
    "                pl.col(\"elapsed_time\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_duration\"),\n",
    "                pl.col(\"index\").filter(\n",
    "                    ((pl.col(\"event_name\") == 'navigate_click') & (pl.col(\"fqid\") == 'journals_flag')) | (\n",
    "                            pl.col(\"fqid\") == \"journals_flag.pic_0.bingo\")).apply(\n",
    "                    lambda s: s.max() - s.min() if s.len() > 0 else 0).alias(\"journalsFlag_bingo_indexCount\")\n",
    "            ]\n",
    "            tmp = x.groupby([\"session_id\"], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "            df = df.join(tmp, on=\"session_id\", how='left')\n",
    "\n",
    "    return df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "535250de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:36.552227Z",
     "iopub.status.busy": "2023-06-28T02:20:36.551377Z",
     "iopub.status.idle": "2023-06-28T02:20:36.566317Z",
     "shell.execute_reply": "2023-06-28T02:20:36.564778Z"
    },
    "papermill": {
     "duration": 0.035706,
     "end_time": "2023-06-28T02:20:36.569821",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.534115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f_read = open('/kaggle/input/cv0604-cv070030-thr062/importance_dict.pkl', 'rb')\n",
    "importance_dict= pickle.load(f_read)\n",
    "f_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5feab68a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:36.605496Z",
     "iopub.status.busy": "2023-06-28T02:20:36.604603Z",
     "iopub.status.idle": "2023-06-28T02:20:36.617555Z",
     "shell.execute_reply": "2023-06-28T02:20:36.616511Z"
    },
    "papermill": {
     "duration": 0.033837,
     "end_time": "2023-06-28T02:20:36.620690",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.586853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f_read = open('/kaggle/input/cv0604-cv070030-thr062/importance_dict_origin.pkl', 'rb')\n",
    "importance_dict_origin= pickle.load(f_read)\n",
    "f_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ba5b80d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:36.659451Z",
     "iopub.status.busy": "2023-06-28T02:20:36.658148Z",
     "iopub.status.idle": "2023-06-28T02:20:39.256638Z",
     "shell.execute_reply": "2023-06-28T02:20:39.255607Z"
    },
    "papermill": {
     "duration": 2.621687,
     "end_time": "2023-06-28T02:20:39.259469",
     "exception": false,
     "start_time": "2023-06-28T02:20:36.637782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_list = []\n",
    "\n",
    "for q in range(1, 19):\n",
    "    fold_models = []\n",
    "    for fold in range(5):\n",
    "        model = XGBClassifier()\n",
    "        model.load_model(f\"/kaggle/input/cv0604-cv070030-thr062/XGB_fold{fold}_q{q}.xgb\")\n",
    "        fold_models.append(model)\n",
    "    models_list.append(fold_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ac5909d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:39.294292Z",
     "iopub.status.busy": "2023-06-28T02:20:39.293183Z",
     "iopub.status.idle": "2023-06-28T02:20:39.299025Z",
     "shell.execute_reply": "2023-06-28T02:20:39.298078Z"
    },
    "papermill": {
     "duration": 0.025295,
     "end_time": "2023-06-28T02:20:39.301616",
     "exception": false,
     "start_time": "2023-06-28T02:20:39.276321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_list = []\n",
    "\n",
    "for t in range(1, 19):\n",
    "        FEATURES_list.append(importance_dict_origin[str(t)].copy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ca68d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:39.336520Z",
     "iopub.status.busy": "2023-06-28T02:20:39.335616Z",
     "iopub.status.idle": "2023-06-28T02:20:39.343280Z",
     "shell.execute_reply": "2023-06-28T02:20:39.340806Z"
    },
    "papermill": {
     "duration": 0.02918,
     "end_time": "2023-06-28T02:20:39.346965",
     "exception": false,
     "start_time": "2023-06-28T02:20:39.317785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Origin feature\n",
    "FEATURES1 = FEATURES_list[0]\n",
    "FEATURES2 = FEATURES_list[4]\n",
    "FEATURES3 = FEATURES_list[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da41ae7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:39.380681Z",
     "iopub.status.busy": "2023-06-28T02:20:39.380195Z",
     "iopub.status.idle": "2023-06-28T02:20:39.386793Z",
     "shell.execute_reply": "2023-06-28T02:20:39.385719Z"
    },
    "papermill": {
     "duration": 0.026763,
     "end_time": "2023-06-28T02:20:39.389839",
     "exception": false,
     "start_time": "2023-06-28T02:20:39.363076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will train with 1134 2130 1150 features\n"
     ]
    }
   ],
   "source": [
    "print('We will train with', len(FEATURES1), len(FEATURES2), len(FEATURES3) ,'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba22adea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:39.423920Z",
     "iopub.status.busy": "2023-06-28T02:20:39.422797Z",
     "iopub.status.idle": "2023-06-28T02:20:39.428726Z",
     "shell.execute_reply": "2023-06-28T02:20:39.427804Z"
    },
    "papermill": {
     "duration": 0.025809,
     "end_time": "2023-06-28T02:20:39.431467",
     "exception": false,
     "start_time": "2023-06-28T02:20:39.405658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES_list_post = []\n",
    "\n",
    "for t in range(1, 19):\n",
    "    FEATURES_list_post.append(importance_dict[str(t)].copy() )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb933938",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:39.466269Z",
     "iopub.status.busy": "2023-06-28T02:20:39.465435Z",
     "iopub.status.idle": "2023-06-28T02:20:39.472499Z",
     "shell.execute_reply": "2023-06-28T02:20:39.471554Z"
    },
    "papermill": {
     "duration": 0.027477,
     "end_time": "2023-06-28T02:20:39.475062",
     "exception": false,
     "start_time": "2023-06-28T02:20:39.447585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3035"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_FEATURES2 = FEATURES_list_post[4]\n",
    "len(joined_FEATURES2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb1be0",
   "metadata": {
    "papermill": {
     "duration": 0.015562,
     "end_time": "2023-06-28T02:20:39.506457",
     "exception": false,
     "start_time": "2023-06-28T02:20:39.490895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51837d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:39.541887Z",
     "iopub.status.busy": "2023-06-28T02:20:39.541011Z",
     "iopub.status.idle": "2023-06-28T02:20:40.644089Z",
     "shell.execute_reply": "2023-06-28T02:20:40.642168Z"
    },
    "papermill": {
     "duration": 1.125198,
     "end_time": "2023-06-28T02:20:40.647725",
     "exception": false,
     "start_time": "2023-06-28T02:20:39.522527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import pickle\n",
    "import polars as pl\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from itertools import combinations\n",
    "import joblib\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ecf3d407",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:40.683810Z",
     "iopub.status.busy": "2023-06-28T02:20:40.682929Z",
     "iopub.status.idle": "2023-06-28T02:20:40.695167Z",
     "shell.execute_reply": "2023-06-28T02:20:40.693989Z"
    },
    "papermill": {
     "duration": 0.033601,
     "end_time": "2023-06-28T02:20:40.698240",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.664639",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CATS_nunique = ['fqid', 'text_fqid', 'name', 'room_fqid', 'event_name']\n",
    "NUMS_mean = ['elapsed_time_diff', 'screen_coor_y', 'hover_duration', 'screen_coor_x', 'room_coor_y', 'page', 'room_coor_x']\n",
    "NUMS_std = ['elapsed_time_diff', 'screen_coor_x', 'room_coor_x', 'screen_coor_y']\n",
    "NUMS_min = ['elapsed_time_diff']\n",
    "NUMS_max = ['room_coor_y']\n",
    "\n",
    "NUMS_median = ['elapsed_time_diff', 'screen_coor_y']\n",
    "NUMS_quantile1 = ['elapsed_time_diff', 'room_coor_y', 'page']\n",
    "NUMS_quantile4 = ['screen_coor_x', 'hover_duration']\n",
    "NUMS_quantile6 = ['elapsed_time_diff']\n",
    "NUMS_quantile7 = ['elapsed_time_diff', 'room_coor_y', 'hover_duration']\n",
    "NUMS_quantile8 = ['elapsed_time_diff']\n",
    "NUMS_quantile9 = ['elapsed_time_diff', 'hover_duration', 'screen_coor_x']\n",
    "\n",
    "fqid_count = ['reader', 'journals.pic_1.next', 'archivist', 'flag_girl', 'journals_flag.pic_0_old.next']\n",
    "fqid_mean = ['logbook.page.bingo', 'coffee', 'chap1_finale_c', 'cs', 'journals_flag.pic_0.next']\n",
    "\n",
    "text_fqid_count = ['tunic.historicalsociety.frontdesk.archivist_glasses.confrontation_recap']\n",
    "text_fqid_mean = ['tunic.historicalsociety.cage.glasses.afterteddy', 'tunic.flaghouse.entry.colorbook']\n",
    "text_fqid_sum = ['tunic.humanecology.frontdesk.worker.intro', 'tunic.library.microfiche.reader_flag.paper2.bingo', 'tunic.historicalsociety.frontdesk.archivist.newspaper', 'tunic.historicalsociety.closet_dirty.trigger_scarf', 'tunic.historicalsociety.stacks.journals.pic_2.bingo', 'tunic.historicalsociety.frontdesk.archivist.have_glass', 'tunic.historicalsociety.cage.unlockdoor']\n",
    "text_fqid_median = ['tunic.wildlife.center.wells.nodeer', 'tunic.historicalsociety.cage.glasses.beforeteddy', 'tunic.wildlife.center.crane_ranger.crane', 'tunic.historicalsociety.frontdesk.key']\n",
    "\n",
    "level1_text_count = [\"Hey Jo, let's take a look at the shirt!\", 'Did you do all of them?', 'So? History is boring!']\n",
    "level1_text_std = ['I gotta run to my meeting!']\n",
    "\n",
    "level2_text_mean = ['Thanks for the help!', \"He's wrong about old shirts and his name rhymes with \\\\smells\\\\...\", \"Well, I can't show our log books to just anybody.\", 'Thanks to them, Wisconsin was the first state to approve votes for women!', 'Now I Just need to find all the cleaners from way back in 1916.', \"It's a match!\", 'Maybe he just got scared and ran off.', 'Nope. But Youmans and other suffragists worked hard to change that.', 'Theodora Youmans must be the owner!', \"I don't need that right now.\", 'Maybe I can help!', \"I'm afraid not.\", 'Okay. Thanks anyway.', \"It's such a nice fall day.\"]\n",
    "\n",
    "\n",
    "level3_text_std = [\"Yes, he has. I've seen him eating homework and important papers, too.\", \"Let's go find Gramps!\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96ff77a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:40.734698Z",
     "iopub.status.busy": "2023-06-28T02:20:40.734213Z",
     "iopub.status.idle": "2023-06-28T02:20:40.759592Z",
     "shell.execute_reply": "2023-06-28T02:20:40.758326Z"
    },
    "papermill": {
     "duration": 0.047518,
     "end_time": "2023-06-28T02:20:40.762726",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.715208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer_LGBM(x, grp, use_extra, feature_suffix):\n",
    "    aggs = [\n",
    "        pl.col(\"index\").count().alias(f\"session_number{feature_suffix}\"),        \n",
    "        \n",
    "        *[pl.col(c).drop_nulls().n_unique().alias(f\"{c}_unique{feature_suffix}\") for c in CATS_nunique],\n",
    "        *[pl.col(c).mean().alias(f\"{c}_mean{feature_suffix}\") for c in NUMS_mean],\n",
    "        *[pl.col(c).std().alias(f\"{c}_std{feature_suffix}\") for c in NUMS_std],\n",
    "        *[pl.col(c).min().alias(f\"{c}_min{feature_suffix}\") for c in NUMS_min],\n",
    "        *[pl.col(c).max().alias(f\"{c}_max{feature_suffix}\") for c in NUMS_max],        \n",
    "        *[pl.col(c).median().alias(f\"{c}_median{feature_suffix}\") for c in NUMS_median],                           \n",
    "    \n",
    "        *[pl.col(c).quantile(0.1, \"nearest\").alias(f\"{c}_quantile1{feature_suffix}\") for c in NUMS_quantile1],\n",
    "        *[pl.col(c).quantile(0.4, \"nearest\").alias(f\"{c}_quantile4{feature_suffix}\") for c in NUMS_quantile4],\n",
    "        *[pl.col(c).quantile(0.6, \"nearest\").alias(f\"{c}_quantile6{feature_suffix}\") for c in NUMS_quantile6],\n",
    "        *[pl.col(c).quantile(0.7, \"nearest\").alias(f\"{c}_quantile7{feature_suffix}\") for c in NUMS_quantile7],\n",
    "        *[pl.col(c).quantile(0.8, \"nearest\").alias(f\"{c}_quantile8{feature_suffix}\") for c in NUMS_quantile8],\n",
    "        *[pl.col(c).quantile(0.9, \"nearest\").alias(f\"{c}_quantile9{feature_suffix}\") for c in NUMS_quantile9],\n",
    "        \n",
    "        *[pl.col(\"fqid\").filter(pl.col(\"fqid\") == c).count().alias(f\"{c}_(fqid)_count{feature_suffix}\") for c in fqid_count], #     \n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).std().alias(f\"{c}_(fqid)_std{feature_suffix}\") for c in fqid_std], # Not improved (50)\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).mean().alias(f\"{c}_(fqid)_mean{feature_suffix}\") for c in fqid_mean],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).sum().alias(f\"{c}_(fqid)_sum{feature_suffix}\") for c in fqid_sum], # Not improved (50)\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).median().alias(f\"{c}_(fqid)_median{feature_suffix}\") for c in fqid_median],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"fqid\") == c).max().alias(f\"{c}_(fqid)_max_{feature_suffix}\") for c in fqid_max],        \n",
    "\n",
    "        *[pl.col(\"text_fqid\").filter(pl.col(\"text_fqid\") == c).count().alias(f\"{c}_(text_fqid)_count{feature_suffix}\") for c in text_fqid_count],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).std().alias(f\"{c}_(text_fqid)_std{feature_suffix}\") for c in text_fqid_std],        \n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).mean().alias(f\"{c}_(text_fqid)_mean{feature_suffix}\") for c in text_fqid_mean],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).sum().alias(f\"{c}_(text_fqid)_sum{feature_suffix}\") for c in text_fqid_sum],        \n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).median().alias(f\"{c}_(text_fqid)_median{feature_suffix}\") for c in text_fqid_median],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text_fqid\") == c).max().alias(f\"{c}_(text_fqid)_max{feature_suffix}\") for c in text_fqid_max],\n",
    "    \n",
    "        # *[pl.col(\"room_fqid\").filter(pl.col(\"room_fqid\") == c).count().alias(f\"{c}_(room_fqid)_count{feature_suffix}\") for c in room_fqid_count],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).std().alias(f\"{c}_(room_fqid)_std{feature_suffix}\") for c in room_fqid_std],\n",
    "#         *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).mean().alias(f\"{c}_(room_fqid)_mean{feature_suffix}\") for c in room_fqid_mean],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).sum().alias(f\"{c}_(room_fqid)_sum{feature_suffix}\") for c in room_fqid_sum],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).median().alias(f\"{c}_(room_fqid)_median{feature_suffix}\") for c in room_fqid_median],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"room_fqid\") == c).max().alias(f\"{c}_(room_fqid)_max{feature_suffix}\") for c in room_fqid_max],\n",
    "        \n",
    "        \n",
    "        *[pl.col(\"text\").filter(pl.col(\"text\") == c).count().alias(f\"{c}_(text1)_count{feature_suffix}\") for c in level1_text_count],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).std().alias(f\"{c}_(text1)_std{feature_suffix}\") for c in level1_text_std],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).mean().alias(f\"{c}_(text1)_mean{feature_suffix}\") for c in level1_text_mean],        \n",
    "#         *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).sum().alias(f\"{c}_(text1)_sum{feature_suffix}\") for c in level1_text_sum],                \n",
    "#         *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).median().alias(f\"{c}_(text1)_median{feature_suffix}\") for c in level1_text_median],        \n",
    "#         *[pl.col(\"elapsed_time_diff\").filter(p\n",
    "        \n",
    "#         *[pl.col(\"text\").filter(pl.col(\"text\") == c).count().alias(f\"{c}_(text2)_count{feature_suffix}\") for c in level2_text_count],\n",
    "#         *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).std().alias(f\"{c}_(text2)_std{feature_suffix}\") for c in level2_text_std],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).mean().alias(f\"{c}_(text2)_mean_{feature_suffix}\") for c in level2_text_mean],\n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).sum().alias(f\"{c}_(text2)_sum{feature_suffix}\") for c in level2_text_sum],\n",
    "#         *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).median().alias(f\"{c}_(text2)_median{feature_suffix}\") for c in level2_text_median],        \n",
    "        # *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).max().alias(f\"{c}_(text2)_max{feature_suffix}\") for c in level2_text_max],\n",
    "        \n",
    "        \n",
    "        \n",
    "#         *[pl.col(\"text\").filter(pl.col(\"text\") == c).count().alias(f\"{c}_(text3)_count{feature_suffix}\") for c in level3_text_count],\n",
    "        *[pl.col(\"elapsed_time_diff\").filter(pl.col(\"text\") == c).std().alias(f\"{c}_(text3)_std{feature_suffix}\") for c in level3_text_std],\n",
    "  \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    ]\n",
    "    \n",
    "    df = x.groupby(['session_id'], maintain_order=True).agg(aggs).sort(\"session_id\")\n",
    "   \n",
    "\n",
    "    return df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e669a18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:40.795852Z",
     "iopub.status.busy": "2023-06-28T02:20:40.795445Z",
     "iopub.status.idle": "2023-06-28T02:20:40.805486Z",
     "shell.execute_reply": "2023-06-28T02:20:40.804298Z"
    },
    "papermill": {
     "duration": 0.030146,
     "end_time": "2023-06-28T02:20:40.808547",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.778401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f_read = open('/kaggle/input/0622-cv069391-thr0625-no-join/importance_dict_origin.pkl', 'rb')\n",
    "importance_dict_origin_LGBM= pickle.load(f_read)\n",
    "f_read.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "831baa0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:40.842512Z",
     "iopub.status.busy": "2023-06-28T02:20:40.842028Z",
     "iopub.status.idle": "2023-06-28T02:20:40.849781Z",
     "shell.execute_reply": "2023-06-28T02:20:40.848510Z"
    },
    "papermill": {
     "duration": 0.028941,
     "end_time": "2023-06-28T02:20:40.853249",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.824308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(importance_dict_origin_LGBM['15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae3c678",
   "metadata": {
    "papermill": {
     "duration": 0.016698,
     "end_time": "2023-06-28T02:20:40.887480",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.870782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc5f2f",
   "metadata": {
    "papermill": {
     "duration": 0.015496,
     "end_time": "2023-06-28T02:20:40.919985",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.904489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3288c3f5",
   "metadata": {
    "papermill": {
     "duration": 0.017653,
     "end_time": "2023-06-28T02:20:40.953644",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.935991",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Infer Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cefb527",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:40.989692Z",
     "iopub.status.busy": "2023-06-28T02:20:40.989270Z",
     "iopub.status.idle": "2023-06-28T02:20:41.011323Z",
     "shell.execute_reply": "2023-06-28T02:20:41.010286Z"
    },
    "papermill": {
     "duration": 0.043486,
     "end_time": "2023-06-28T02:20:41.014192",
     "exception": false,
     "start_time": "2023-06-28T02:20:40.970706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jo_wilder\n",
    "\n",
    "try:\n",
    "    jo_wilder.make_env.__called__ = False\n",
    "    env.__called__ = False\n",
    "    type(env)._state = type(type(env)._state).__dict__['INIT']\n",
    "except:\n",
    "    pass\n",
    "\n",
    "env = jo_wilder.make_env()\n",
    "iter_test = env.iter_test()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e381e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:41.048244Z",
     "iopub.status.busy": "2023-06-28T02:20:41.047817Z",
     "iopub.status.idle": "2023-06-28T02:20:41.053118Z",
     "shell.execute_reply": "2023-06-28T02:20:41.052113Z"
    },
    "papermill": {
     "duration": 0.025263,
     "end_time": "2023-06-28T02:20:41.055728",
     "exception": false,
     "start_time": "2023-06-28T02:20:41.030465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cb77b93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:20:41.090725Z",
     "iopub.status.busy": "2023-06-28T02:20:41.089459Z",
     "iopub.status.idle": "2023-06-28T02:21:11.787032Z",
     "shell.execute_reply": "2023-06-28T02:21:11.785487Z"
    },
    "papermill": {
     "duration": 30.718574,
     "end_time": "2023-06-28T02:21:11.790346",
     "exception": false,
     "start_time": "2023-06-28T02:20:41.071772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "1134\n",
      "question 1 threshold: 0.625\n",
      "1135\n",
      "1136\n",
      "question 3 threshold: 0.62\n",
      "3038\n",
      "question 4 threshold: 0.605\n",
      "3039\n",
      "question 5 threshold: 0.62\n",
      "3040\n",
      "question 6 threshold: 0.615\n",
      "3041\n",
      "question 7 threshold: 0.62\n",
      "3042\n",
      "question 8 threshold: 0.62\n",
      "3043\n",
      "question 9 threshold: 0.595\n",
      "3044\n",
      "question 10 threshold: 0.625\n",
      "3045\n",
      "question 11 threshold: 0.625\n",
      "3046\n",
      "3047\n",
      "4164\n",
      "question 14 threshold: 0.62\n",
      "4165\n",
      "question 15 threshold: 0.62\n",
      "4166\n",
      "question 16 threshold: 0.62\n",
      "4167\n",
      "question 17 threshold: 0.615\n",
      "4168\n",
      "1134\n",
      "question 1 threshold: 0.625\n",
      "1135\n",
      "1136\n",
      "question 3 threshold: 0.62\n",
      "3038\n",
      "question 4 threshold: 0.605\n",
      "3039\n",
      "question 5 threshold: 0.62\n",
      "3040\n",
      "question 6 threshold: 0.615\n",
      "3041\n",
      "question 7 threshold: 0.62\n",
      "3042\n",
      "question 8 threshold: 0.62\n",
      "3043\n",
      "question 9 threshold: 0.595\n",
      "3044\n",
      "question 10 threshold: 0.625\n",
      "3045\n",
      "question 11 threshold: 0.625\n",
      "3046\n",
      "3047\n",
      "4164\n",
      "question 14 threshold: 0.62\n",
      "4165\n",
      "question 15 threshold: 0.62\n",
      "4166\n",
      "question 16 threshold: 0.62\n",
      "4167\n",
      "question 17 threshold: 0.615\n",
      "4168\n",
      "1134\n",
      "question 1 threshold: 0.625\n",
      "1135\n",
      "1136\n",
      "question 3 threshold: 0.62\n",
      "3038\n",
      "question 4 threshold: 0.605\n",
      "3039\n",
      "question 5 threshold: 0.62\n",
      "3040\n",
      "question 6 threshold: 0.615\n",
      "3041\n",
      "question 7 threshold: 0.62\n",
      "3042\n",
      "question 8 threshold: 0.62\n",
      "3043\n",
      "question 9 threshold: 0.595\n",
      "3044\n",
      "question 10 threshold: 0.625\n",
      "3045\n",
      "question 11 threshold: 0.625\n",
      "3046\n",
      "3047\n",
      "4164\n",
      "question 14 threshold: 0.62\n",
      "4165\n",
      "question 15 threshold: 0.62\n",
      "4166\n",
      "question 16 threshold: 0.62\n",
      "4167\n",
      "question 17 threshold: 0.615\n",
      "4168\n"
     ]
    }
   ],
   "source": [
    "limits = {'0-4':(1,4), '5-12':(4,14), '13-22':(14,19)}\n",
    "g_end4 = 0\n",
    "g_end5 = 0\n",
    "list_q = {'0-4':quests_0_4, '5-12':quests_5_12, '13-22':quests_13_22}\n",
    "######################### xgboost ############\n",
    "# Remember to change the threshold\n",
    "\n",
    "# [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17] -1  .\n",
    "best_threshold_lists = [0.625, 0.62, 0.620, 0.605, 0.620, 0.615, 0.620, 0.620, 0.595, 0.625, 0.625, 0.62, 0.62, 0.620, 0.620, 0.620, 0.615, 0.62]\n",
    "fold = 0\n",
    "\n",
    "session_features = defaultdict(dict)\n",
    "historical_meta = defaultdict(list)\n",
    "historical_meta_LGBM = defaultdict(list)\n",
    "\n",
    "################################\n",
    "for (test, sam_sub) in iter_test:\n",
    "    test0 = test.copy()\n",
    "    test0 = test0.sort_values('index') # elapsed_time  sorting\n",
    "        \n",
    "    sam_sub['question'] = [int(label.split('_')[1][1:]) for label in sam_sub['session_id']]    \n",
    "    grp = test.level_group.values[0]   \n",
    "    sam_sub['correct'] = 1\n",
    "    sam_sub.loc[sam_sub.question.isin([5, 8, 10, 13, 15]), 'correct'] = 0  \n",
    "    old_train = delt_time_def(test[test.level_group == grp])\n",
    "    \n",
    "    ##################### XGBoost #######################################\n",
    "    grp = test0.level_group.values[0]\n",
    "    session_id = test0.session_id.values[0]\n",
    "    sam_sub['question'] = [int(label.split('_')[1][1:]) for label in sam_sub['session_id']]\n",
    "    columns = [\n",
    "        pl.col(\"page\").cast(pl.Float32),\n",
    "        (\n",
    "            (pl.col(\"elapsed_time\") - pl.col(\"elapsed_time\").shift(1))\n",
    "            .fill_null(0)        \n",
    "            .clip(0, 1e8)\n",
    "            .over([\"session_id\", \"level\"])\n",
    "            .alias(\"elapsed_time_diff\")\n",
    "        ),\n",
    "        (\n",
    "            (pl.col(\"screen_coor_x\") - pl.col(\"screen_coor_x\").shift(1))\n",
    "            .abs()\n",
    "            .over([\"session_id\", \"level\"])\n",
    "        ),\n",
    "        (\n",
    "            (pl.col(\"screen_coor_y\") - pl.col(\"screen_coor_y\").shift(1))\n",
    "            .abs()\n",
    "            .over([\"session_id\", \"level\"])\n",
    "        ),\n",
    "        pl.col(\"fqid\").fill_null(\"fqid_None\"),\n",
    "        pl.col(\"text_fqid\").fill_null(\"text_fqid_None\"),\n",
    "        pl.col('text').fill_null('text_None')\n",
    "\n",
    "    ]\n",
    "\n",
    "    test0 = (pl.from_pandas(test0)\n",
    "          .drop([\"fullscreen\", \"hq\", \"music\"])\n",
    "          .with_columns(columns))\n",
    "    \n",
    "    # FEATURE ENGINEER TEST DATA\n",
    "    test0_featured = feature_engineer_xgboost(test0, grp, use_extra=True, feature_suffix='')\n",
    "    \n",
    "    # FEATURE ENGINEER TEST DATA\n",
    "    test0_LGBM = feature_engineer_LGBM(test0, grp, use_extra=True, feature_suffix='')\n",
    "\n",
    "    \n",
    "#     print(grp)\n",
    "    # Save features\n",
    "    session_features[session_id][grp] = test0_featured.copy()\n",
    "    # Load features\n",
    "    if grp == '0-4':\n",
    "        pass\n",
    "    elif grp == '5-12':\n",
    "        df1 = session_features[session_id]['0-4'][FEATURES1].copy()\n",
    "        df2 = test0_featured[FEATURES2].copy()                                \n",
    "        df_joined = df1.join(df2, lsuffix='_df1', rsuffix='_df2')        \n",
    "        test0_featured = df_joined\n",
    "    else:\n",
    "        df1 = session_features[session_id]['0-4'][FEATURES1].copy()\n",
    "        df2 = session_features[session_id]['5-12'][FEATURES2].copy()\n",
    "        df_joined_2 = df1.join(df2, lsuffix='_df1', rsuffix='_df2')     \n",
    "                                                \n",
    "        df3 = test0_featured[FEATURES3].copy()     \n",
    "        \n",
    "        df_joined_3 = df_joined_2[joined_FEATURES2].join(df3, lsuffix='_joined_df2', rsuffix='_df3')\n",
    "        test0_featured = df_joined_3\n",
    "    \n",
    "                    \n",
    "    a,b = limits[grp]\n",
    "    for q in range(a, b):\n",
    "    # for q in list_q[grp]:        \n",
    "        if q in [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17]:\n",
    "            start4 = time.time()\n",
    "            new_train = feature_engineer(old_train, list_kol_f[q])\n",
    "            new_train = feature_quest_otvet(new_train, old_train, q, list_kol_f[q])\n",
    "    #         new_train = feature_quest(new_train, old_train, q, kol_f)\n",
    "\n",
    "            end4 = time.time() - start4\n",
    "            g_end4 += end4\n",
    "\n",
    "            start5 = time.time()        \n",
    "\n",
    "            clf = models[f'{q}']\n",
    "            p1 = clf.predict_proba(new_train.astype('float32'))[:,1]        \n",
    "\n",
    "            end5 = time.time() - start5\n",
    "            g_end5 += end5\n",
    "\n",
    "\n",
    "            mask = sam_sub.question == q\n",
    "            # x1 = int(p[0]>best_threshold)\n",
    "            x1 = p1[0]\n",
    "        \n",
    "        ################################## xgboost #########################\n",
    "        FEATURES = importance_dict[str(q)].copy()\n",
    "        \n",
    "        # Load the previous model predictions if available\n",
    "        if q > 1:\n",
    "            for prev_t in range(1, q):\n",
    "                # Add the previous model predictions as feature\n",
    "                test0_featured[f'prev_pred_{prev_t}'] = historical_meta[session_id][prev_t - 1]\n",
    "            FEATURES += [f'prev_pred_{prev_t}' for prev_t in range(1, q)]\n",
    "        \n",
    "        print(len(FEATURES))\n",
    "        \n",
    "        model_0 = models_list[q-1][fold]\n",
    "        model_1 = models_list[q-1][fold+1]\n",
    "        model_2 = models_list[q-1][fold+2]\n",
    "        model_3 = models_list[q-1][fold+3]\n",
    "        model_4 = models_list[q-1][fold+4]                                \n",
    "        \n",
    "        \n",
    "        pred_0 = model_0.predict_proba(np.array(test0_featured[FEATURES]).astype('float32'))[:,1]\n",
    "        pred_1 = model_1.predict_proba(np.array(test0_featured[FEATURES]).astype('float32'))[:,1]\n",
    "        pred_2 = model_2.predict_proba(np.array(test0_featured[FEATURES]).astype('float32'))[:,1]\n",
    "        pred_3 = model_3.predict_proba(np.array(test0_featured[FEATURES]).astype('float32'))[:,1]\n",
    "        pred_4 = model_4.predict_proba(np.array(test0_featured[FEATURES]).astype('float32'))[:,1]\n",
    "        \n",
    "        p2 = (pred_0 + pred_1 + pred_2 + pred_3 + pred_4) / 5\n",
    "        \n",
    "        # Store the prediction for future use\n",
    "        historical_meta[session_id].append(p2)\n",
    "        ########################### LGBM: LB 0.692 #############################        \n",
    "        FEATURES_LGBM = importance_dict_origin_LGBM[str(q)].copy() \n",
    "        \n",
    "        if q > 1:\n",
    "            for prev_q in range(1, q):\n",
    "                # Add the previous model predictions as feature\n",
    "                test0_LGBM[f'prev_pred_{prev_q}'] = historical_meta_LGBM[session_id][prev_q - 1]\n",
    "            FEATURES_LGBM += [f'prev_pred_{prev_q}' for prev_q in range(1, q)]                    \n",
    "        \n",
    "        model0 = joblib.load(f'/kaggle/input/0622-cv069391-thr0625-no-join/LGBM_fold0_q{q}.pkl') # fold 0\n",
    "        model1 = joblib.load(f'/kaggle/input/0622-cv069391-thr0625-no-join/LGBM_fold1_q{q}.pkl') # fold 1\n",
    "        model2 = joblib.load(f'/kaggle/input/0622-cv069391-thr0625-no-join/LGBM_fold2_q{q}.pkl') # fold 2\n",
    "        model3 = joblib.load(f'/kaggle/input/0622-cv069391-thr0625-no-join/LGBM_fold3_q{q}.pkl') # fold 3\n",
    "        model4 = joblib.load(f'/kaggle/input/0622-cv069391-thr0625-no-join/LGBM_fold4_q{q}.pkl') # fold 4\n",
    "        \n",
    "        p_0 = model0.predict_proba(np.array(test0_LGBM[FEATURES_LGBM]).astype('float32'))[:,1]\n",
    "        p_1 = model1.predict_proba(np.array(test0_LGBM[FEATURES_LGBM]).astype('float32'))[:,1]\n",
    "        p_2 = model2.predict_proba(np.array(test0_LGBM[FEATURES_LGBM]).astype('float32'))[:,1]\n",
    "        p_3 = model3.predict_proba(np.array(test0_LGBM[FEATURES_LGBM]).astype('float32'))[:,1]\n",
    "        p_4 = model4.predict_proba(np.array(test0_LGBM[FEATURES_LGBM]).astype('float32'))[:,1]\n",
    "        \n",
    "        p3 = (p_0 + p_1 + p_2 + p_3 + p_4) / 5   \n",
    "        \n",
    "        historical_meta_LGBM[session_id].append(p3)\n",
    "        \n",
    "        #  14 threshold\n",
    "        if q in [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17]: #   Ensemble\n",
    "            x2 = p2\n",
    "            x3 = p3\n",
    "        ################################# Ensemble ###################################\n",
    "            # XGboost weight: 0.89, catboost weight: 0.09, LGBM: 0.02\n",
    "            # x = (x1 * 0.1) + (x2 * 0.9)\n",
    "            x = (x1 * 0.09) + (x2 * 0.89) + (x3 * 0.02)\n",
    "            print(f'question {q} threshold: {best_threshold_lists[q-1]}')\n",
    "            sam_sub.loc[mask,'correct'] = (x > best_threshold_lists[q-1]).astype('int')\n",
    " \n",
    "    sam_sub = sam_sub[['session_id', 'correct']]          \n",
    "    env.predict(sam_sub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7821ae9f",
   "metadata": {
    "papermill": {
     "duration": 0.024565,
     "end_time": "2023-06-28T02:21:11.838912",
     "exception": false,
     "start_time": "2023-06-28T02:21:11.814347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a1bcd44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:21:11.893566Z",
     "iopub.status.busy": "2023-06-28T02:21:11.891858Z",
     "iopub.status.idle": "2023-06-28T02:21:11.905670Z",
     "shell.execute_reply": "2023-06-28T02:21:11.904538Z"
    },
    "papermill": {
     "duration": 0.046924,
     "end_time": "2023-06-28T02:21:11.910040",
     "exception": false,
     "start_time": "2023-06-28T02:21:11.863116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090312331414616_q14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090312331414616_q15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090312331414616_q16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090312331414616_q17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090312331414616_q18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              session_id  correct\n",
       "0  20090312331414616_q14        1\n",
       "1  20090312331414616_q15        1\n",
       "2  20090312331414616_q16        1\n",
       "3  20090312331414616_q17        1\n",
       "4  20090312331414616_q18        1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sam_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a97cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:21:11.961489Z",
     "iopub.status.busy": "2023-06-28T02:21:11.960585Z",
     "iopub.status.idle": "2023-06-28T02:21:11.977529Z",
     "shell.execute_reply": "2023-06-28T02:21:11.976329Z"
    },
    "papermill": {
     "duration": 0.044353,
     "end_time": "2023-06-28T02:21:11.980258",
     "exception": false,
     "start_time": "2023-06-28T02:21:11.935905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 2) 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20090109393214576_q1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20090109393214576_q2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20090109393214576_q3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20090109393214576_q4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20090109393214576_q5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             session_id  correct\n",
       "0  20090109393214576_q1        1\n",
       "1  20090109393214576_q2        1\n",
       "2  20090109393214576_q3        1\n",
       "3  20090109393214576_q4        1\n",
       "4  20090109393214576_q5        0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv('./submission.csv')\n",
    "# print(sub.correct.mean())\n",
    "\n",
    "print(sub.shape, sub.correct.mean())\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e17c91f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T02:21:12.028338Z",
     "iopub.status.busy": "2023-06-28T02:21:12.027299Z",
     "iopub.status.idle": "2023-06-28T02:21:12.032233Z",
     "shell.execute_reply": "2023-06-28T02:21:12.031220Z"
    },
    "papermill": {
     "duration": 0.032244,
     "end_time": "2023-06-28T02:21:12.035108",
     "exception": false,
     "start_time": "2023-06-28T02:21:12.002864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('submission.csv')\n",
    "# print( df.shape )\n",
    "# df.head(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 985.854405,
   "end_time": "2023-06-28T02:21:13.289295",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-28T02:04:47.434890",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
